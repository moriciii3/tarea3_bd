{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Tarea 3 MongoDB, arXiv\n",
        "##### Integrantes:\n",
        "Bruno Morici, ROL: 202373555-8,\n",
        "Martin Aranda, ROL: 202373021-1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLP_JWcpkpxb"
      },
      "source": [
        "## Primera Etapa\n",
        "Instalación de dependencias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjQ3LC2IKV5T",
        "outputId": "49b89894-2894-495c-8130-73fbc4804ab7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pymongo in c:\\users\\bruno\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.13.0)\n",
            "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in c:\\users\\bruno\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pymongo) (2.7.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.3.1 -> 25.1.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tqdm in c:\\users\\bruno\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.67.1)\n",
            "Requirement already satisfied: colorama in c:\\users\\bruno\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm) (0.4.6)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.3.1 -> 25.1.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "# Instalamos dependencias\n",
        "!pip install pymongo\n",
        "!pip install tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Segunda Etapa\n",
        "Conexión a la BD \"arxiv_db\" y creación de colección \"articles\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Conexión exitosa\n",
            "Primario: ('mongo1', 27017)\n"
          ]
        }
      ],
      "source": [
        "from pymongo import MongoClient\n",
        "\n",
        "# Conexión a Replica Set con preferencia al primario\n",
        "client = MongoClient(\"mongodb://mongo1:27017,mongo2:27017,mongo3:27017/?replicaSet=rs0\")\n",
        "\n",
        "db = client[\"arxiv_db\"]\n",
        "collection = db[\"articles\"]\n",
        "\n",
        "try:\n",
        "    server_info = client.server_info()\n",
        "    print(\"✅ Conexión exitosa\")\n",
        "    print(f\"Primario: {client.primary}\") # El cliente retorna un primario mal detectado, es normal, pero las escrituras se realizan sobre mongo1\n",
        "except Exception as e:\n",
        "    print(f\"❌ Error de conexión: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Tercera Etapa\n",
        "Procesamiento del dataset hacia la BD (ejecutar una sola vez, luego los datos quedan en la BD)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Observación: El dataset tiene un JSON en cada línea, no es una lista de JSON's. Recorremos cada JSON, lo parseamos y guardamos en una lista de data (demora unos 6 minutos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "GU00dCWikwRA",
        "outputId": "7a5a8ae0-4d89-4ede-9fe9-3383a567aca6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iniciando carga de datos a MongoDB...\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 39\u001b[39m\n\u001b[32m     35\u001b[39m             total_docs += \u001b[38;5;28mlen\u001b[39m(batch)\n\u001b[32m     37\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mTotal de documentos insertados: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_docs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m \u001b[43mload_data_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Llamamos la funcion creada anteriormente\u001b[39;00m\n\u001b[32m     41\u001b[39m \u001b[38;5;66;03m# 3. Verificacion final\u001b[39;00m\n\u001b[32m     42\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mResumen de la base de datos:\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 14\u001b[39m, in \u001b[36mload_data_batch\u001b[39m\u001b[34m(batch_size)\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Primero contamos las lineas para la barra de progreso\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[33m'\u001b[39m\u001b[33marxiv-metadata-oai-snapshot.json\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m, encoding=\u001b[33m'\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m     total_lines = \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# Insertamos los datos en el batch\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[33m'\u001b[39m\u001b[33marxiv-metadata-oai-snapshot.json\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m, encoding=\u001b[33m'\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 14\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Primero contamos las lineas para la barra de progreso\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[33m'\u001b[39m\u001b[33marxiv-metadata-oai-snapshot.json\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m, encoding=\u001b[33m'\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m     total_lines = \u001b[38;5;28msum\u001b[39m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# Insertamos los datos en el batch\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[33m'\u001b[39m\u001b[33marxiv-metadata-oai-snapshot.json\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m, encoding=\u001b[33m'\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m<frozen codecs>:319\u001b[39m, in \u001b[36mdecode\u001b[39m\u001b[34m(self, input, final)\u001b[39m\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "import json\n",
        "from tqdm import tqdm # Para mostrar una barra de progreso\n",
        "\n",
        "# Cargar y procesar el archivo JSON\n",
        "print(\"Iniciando carga de datos a MongoDB...\")\n",
        "\n",
        "# Carga por lotes de 1000 en 1000\n",
        "def load_data_batch(batch_size=1000):\n",
        "    batch = []\n",
        "    total_docs = 0\n",
        "    \n",
        "    # Primero contamos las lineas para la barra de progreso\n",
        "    with open('arxiv-metadata-oai-snapshot.json', 'r', encoding='utf-8') as f:\n",
        "        total_lines = sum(1 for _ in f)\n",
        "    \n",
        "    # Insertamos los datos en el batch\n",
        "    with open('arxiv-metadata-oai-snapshot.json', 'r', encoding='utf-8') as f:\n",
        "        for line in tqdm(f, total=total_lines, desc=\"Cargando datos\"):\n",
        "            record = json.loads(line)\n",
        "            # Agregamos el campo pdf_source\n",
        "            if \"id\" in record:\n",
        "                record[\"pdf_source\"] = f\"https://arxiv.org/pdf/{record['id']}\"\n",
        "\n",
        "            batch.append(record)\n",
        "            \n",
        "            # Si el batch excede el maximo, lo vaciamos e insertamos los datos en la BD\n",
        "            if len(batch) >= batch_size:\n",
        "                collection.insert_many(batch)\n",
        "                total_docs += len(batch)\n",
        "                batch = []\n",
        "        \n",
        "        # Insertar el ultimo lote, en caso de que el ultimo lote sean menos de 1000\n",
        "        if batch:\n",
        "            collection.insert_many(batch)\n",
        "            total_docs += len(batch)\n",
        "    \n",
        "    print(f\"\\nTotal de documentos insertados: {total_docs}\")\n",
        "\n",
        "load_data_batch() # Llamamos la funcion creada anteriormente\n",
        "\n",
        "# 3. Verificacion final\n",
        "print(\"\\nResumen de la base de datos:\")\n",
        "print(f\"- Colección: {collection.name}\")    \n",
        "print(f\"- Ejemplo de documento: {collection.find_one()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "📦 Documentos estimados en mongo1: 2744489\n",
            "📦 Documentos estimados en mongo2: 2744489\n",
            "📦 Documentos estimados en mongo3: 2744489\n"
          ]
        }
      ],
      "source": [
        "ports = [27017, 27018, 27019]\n",
        "for i, port in enumerate(ports, start=1):\n",
        "    client = MongoClient(f\"mongodb://localhost:{port}\")\n",
        "    count = client[\"arxiv_db\"][\"articles\"].estimated_document_count()\n",
        "    print(f\"📦 Documentos estimados en mongo{i}: {count}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cuarta etapa: Consultas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Consulta test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🟢 mongo1 (27017) - Artículos con 'Software':\n",
            "   🔹 Solar Magnetic Tracking. I. Software Comparison and Recommended\n",
            "  Practices\n",
            "   🔹 On How Developers Test Open Source Software Systems\n",
            "   🔹 Experiences of Engineering Grid-Based Medical Software\n",
            "--------------------------------------------------\n",
            "🟢 mongo2 (27018) - Artículos con 'Software':\n",
            "   🔹 Solar Magnetic Tracking. I. Software Comparison and Recommended\n",
            "  Practices\n",
            "   🔹 On How Developers Test Open Source Software Systems\n",
            "   🔹 Experiences of Engineering Grid-Based Medical Software\n",
            "--------------------------------------------------\n",
            "🟢 mongo3 (27019) - Artículos con 'Software':\n",
            "   🔹 Solar Magnetic Tracking. I. Software Comparison and Recommended\n",
            "  Practices\n",
            "   🔹 On How Developers Test Open Source Software Systems\n",
            "   🔹 Experiences of Engineering Grid-Based Medical Software\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "def buscar_software(port, nombre):\n",
        "    try:\n",
        "        client = MongoClient(f\"mongodb://localhost:{port}\", serverSelectionTimeoutMS=5000)\n",
        "        db = client[\"arxiv_db\"]\n",
        "        collection = db[\"articles\"]\n",
        "\n",
        "        resultados = collection.find(\n",
        "            {\"title\": {\"$regex\": \"Software\", \"$options\": \"i\"}},\n",
        "            {\"_id\": 0, \"title\": 1}\n",
        "        ).limit(3)  # solo para mostrar pocos\n",
        "\n",
        "        print(f\"🟢 {nombre} ({port}) - Artículos con 'Software':\")\n",
        "        encontrados = False\n",
        "        for doc in resultados:\n",
        "            print(f\"   🔹 {doc['title']}\")\n",
        "            encontrados = True\n",
        "        if not encontrados:\n",
        "            print(\"   ⚠️ No se encontraron artículos.\")\n",
        "        print(\"-\" * 50)\n",
        "    except Exception as e:\n",
        "        print(f\"🔴 Error en {nombre} ({port}): {e}\")\n",
        "\n",
        "# Ejecutar búsqueda en los tres nodos\n",
        "buscar_software(27017, \"mongo1\")\n",
        "buscar_software(27018, \"mongo2\")\n",
        "buscar_software(27019, \"mongo3\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Consulta 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1. Título: IGC: Integrating a Gated Calculator into an LLM to Solve Arithmetic\n",
            "  Tasks Reliably and Efficiently\n",
            "Primera versión (v1): Wed, 1 Jan 2025 00:01:27 GMT\n",
            "--------------------------------------------------\n",
            "2. Título: A quantization of coarse spaces and uniform Roe algebras\n",
            "Primera versión (v1): Wed, 1 Jan 2025 00:04:43 GMT\n",
            "--------------------------------------------------\n",
            "3. Título: NIOS II Soft-Core Processor and Ethernet Controller Solution for RPC-DAQ\n",
            "  in INO ICAL\n",
            "Primera versión (v1): Wed, 1 Jan 2025 00:37:15 GMT\n",
            "--------------------------------------------------\n",
            "4. Título: Minkowski problem of anisotropic p-torsional rigidity\n",
            "Primera versión (v1): Wed, 1 Jan 2025 00:38:34 GMT\n",
            "--------------------------------------------------\n",
            "5. Título: Gravitational Instantons, old and new\n",
            "Primera versión (v1): Wed, 1 Jan 2025 00:38:55 GMT\n",
            "--------------------------------------------------\n",
            "6. Título: Finite groups with exactly two nonlinear irreducible $p$-Brauer\n",
            "  characters\n",
            "Primera versión (v1): Wed, 1 Jan 2025 00:56:25 GMT\n",
            "--------------------------------------------------\n",
            "7. Título: Enhanced Dissipation, Taylor Dispersion, and Inviscid Damping of Couette\n",
            "  flow in the Boussinesq system on the Plane\n",
            "Primera versión (v1): Wed, 1 Jan 2025 00:57:34 GMT\n",
            "--------------------------------------------------\n",
            "8. Título: Labels Generated by Large Language Model Helps Measuring People's\n",
            "  Empathy in Vitro\n",
            "Primera versión (v1): Wed, 1 Jan 2025 01:06:58 GMT\n",
            "--------------------------------------------------\n",
            "9. Título: Adjoint sharding for very long context training of state space models\n",
            "Primera versión (v1): Wed, 1 Jan 2025 01:10:59 GMT\n",
            "--------------------------------------------------\n",
            "10. Título: Beyond Model Scale Limits: End-Edge-Cloud Federated Learning with\n",
            "  Self-Rectified Knowledge Agglomeration\n",
            "Primera versión (v1): Wed, 1 Jan 2025 01:11:16 GMT\n",
            "--------------------------------------------------\n",
            "11. Título: Cosymplectic Lagrangian-like submanifolds\n",
            "Primera versión (v1): Wed, 1 Jan 2025 01:14:16 GMT\n",
            "--------------------------------------------------\n",
            "12. Título: Theory and Applications of Kernel Stein Discrepancy on Riemannian\n",
            "  Manifolds\n",
            "Primera versión (v1): Wed, 1 Jan 2025 01:21:38 GMT\n",
            "--------------------------------------------------\n",
            "13. Título: Cost and Reward Infused Metric Elicitation\n",
            "Primera versión (v1): Wed, 1 Jan 2025 01:36:49 GMT\n",
            "--------------------------------------------------\n",
            "14. Título: PANDA -- Paired Anti-hate Narratives Dataset from Asia: Using an\n",
            "  LLM-as-a-Judge to Create the First Chinese Counterspeech Dataset\n",
            "Primera versión (v1): Wed, 1 Jan 2025 01:56:32 GMT\n",
            "--------------------------------------------------\n",
            "15. Título: A Ritz variational principle for local collisionless gyrokinetic\n",
            "  instabilities\n",
            "Primera versión (v1): Wed, 1 Jan 2025 02:15:18 GMT\n",
            "--------------------------------------------------\n",
            "16. Título: Unconventional Coherence Peak in Cuprate Superconductors\n",
            "Primera versión (v1): Wed, 1 Jan 2025 02:17:21 GMT\n",
            "--------------------------------------------------\n",
            "17. Título: Knowledge-Guided Prompt Learning for Deepfake Facial Image Detection\n",
            "Primera versión (v1): Wed, 1 Jan 2025 02:18:18 GMT\n",
            "--------------------------------------------------\n",
            "18. Título: ResKoopNet: Learning Koopman Representations for Complex Dynamics with\n",
            "  Spectral Residuals\n",
            "Primera versión (v1): Wed, 1 Jan 2025 02:19:42 GMT\n",
            "--------------------------------------------------\n",
            "19. Título: Trading linearity for ellipticity: a nonsmooth approach to Einstein's\n",
            "  theory of gravity and the Lorentzian splitting theorems\n",
            "Primera versión (v1): Wed, 1 Jan 2025 02:24:51 GMT\n",
            "--------------------------------------------------\n",
            "20. Título: Information geometry for types in the large-$n$ limit of random matrices\n",
            "Primera versión (v1): Wed, 1 Jan 2025 02:27:03 GMT\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def leer_articulos_2025(collection):\n",
        "    try:\n",
        "        # Defino lo que queremos buscar en base a la filtro del año 2025\n",
        "        cursor = collection.find(\n",
        "            {\"versions.0.created\": {\"$regex\": r\"2025\"}},\n",
        "            {\"title\": 1, \"versions\": 1}).limit(20)\n",
        "        \n",
        "        art = []\n",
        "\n",
        "        # Agregamos todo lo recolectado en una lista\n",
        "        for doc in cursor:\n",
        "            art.append({\n",
        "                \"title\": doc.get(\"title\", \"No title\"),\n",
        "                \"versions\": doc.get(\"versions\", [])\n",
        "            })\n",
        "        \n",
        "        return art\n",
        "    except Exception as e:\n",
        "        print(f\"Error al leer artículos de 2025: {e}\")\n",
        "        return []\n",
        "    \n",
        "resultado = leer_articulos_2025(collection)\n",
        "i = 1\n",
        "for elem in resultado:\n",
        "    print(f\"{i}. Título: {elem.get('title', '(sin título)')}\")\n",
        "    primera_version = elem.get('versions', [{}])[0]\n",
        "    fecha = primera_version.get('created', '¿sin fecha?')\n",
        "    print(f\"   Primera versión (v1): {fecha}\")\n",
        "    print(\"-\" * 50)\n",
        "    i += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Consulta 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Artículos en cs.AI o stat.ML con al menos 3 autores:\n",
            "1. Título: Calculating Valid Domains for BDD-Based Interactive Configuration\n",
            "   Autores: ['Tarik Hadzic', 'Rune Moller Jensen', 'Henrik Reif Andersen']\n",
            "----------------------------------------\n",
            "2. Título: Personalizing Image Search Results on Flickr\n",
            "   Autores: ['Kristina Lerman', 'Anon Plangprasopchok', 'Chio Wong']\n",
            "----------------------------------------\n",
            "3. Título: Unicast and Multicast Qos Routing with Soft Constraint Logic Programming\n",
            "   Autores: ['Stefano Bistarelli', 'Ugo Montanari', 'Francesca Rossi', 'Francesco Santini']\n",
            "----------------------------------------\n",
            "4. Título: A study of structural properties on profiles HMMs\n",
            "   Autores: ['Juliana S Bernardes', 'Alberto Davila', 'Vitor Santos Costa', 'Gerson\\n  Zaverucha']\n",
            "----------------------------------------\n",
            "5. Título: Introduction to Arabic Speech Recognition Using CMUSphinx System\n",
            "   Autores: ['H. Satori', 'M. Harti', 'N. Chenfour']\n",
            "----------------------------------------\n",
            "6. Título: Arabic Speech Recognition System using CMU-Sphinx4\n",
            "   Autores: ['H. Satori', 'M. Harti', 'N. Chenfour']\n",
            "----------------------------------------\n",
            "7. Título: Experimenting with recursive queries in database and logic programming\n",
            "  systems\n",
            "   Autores: ['Giorgio Terracina', 'Nicola Leone', 'Vincenzino Lio', 'Claudio Panetta']\n",
            "----------------------------------------\n",
            "8. Título: An Adaptive Strategy for the Classification of G-Protein Coupled\n",
            "  Receptors\n",
            "   Autores: ['S. Mohamed', 'D. Rubin', 'and T. Marwala']\n",
            "----------------------------------------\n",
            "9. Título: Comparing Robustness of Pairwise and Multiclass Neural-Network Systems\n",
            "  for Face Recognition\n",
            "   Autores: ['J. Uglov', 'V. Schetinin', 'C. Maple']\n",
            "----------------------------------------\n",
            "10. Título: Ensemble Learning for Free with Evolutionary Algorithms ?\n",
            "   Autores: [\"Christian Gagn\\\\'e (INFORMATIQUE WGZ INC.)\", 'Mich\\\\`ele Sebag (INRIA\\n  Futurs)', 'Marc Schoenauer (INRIA Futurs)', 'Marco Tomassini (ISI)']\n",
            "----------------------------------------\n"
          ]
        }
      ],
      "source": [
        "def buscar_articulos_csai_statml_3autores(collection):\n",
        "    try:\n",
        "        cursor = collection.find(\n",
        "            {\n",
        "                \"$or\": [\n",
        "                    {\"categories\": {\"$regex\": r\"cs\\.AI\"}},\n",
        "                    {\"categories\": {\"$regex\": r\"stat\\.ML\"}}\n",
        "                ]\n",
        "            },\n",
        "            {\"_id\": 0, \"title\": 1, \"authors\": 1}\n",
        "        ).limit(100)  # buscamos más para filtrar en Python\n",
        "\n",
        "        resultados = []\n",
        "\n",
        "        for doc in cursor:\n",
        "            authors_str = doc.get(\"authors\", \"\")\n",
        "            # separar autores por coma o \"and\"\n",
        "            autores = []\n",
        "            if authors_str:\n",
        "                # primero separar por comas\n",
        "                partes = [a.strip() for a in authors_str.split(\",\")]\n",
        "                # cada parte puede contener 'and', dividirlas también\n",
        "                for parte in partes:\n",
        "                    autores.extend([x.strip() for x in parte.split(\" and \") if x.strip() != \"\"])\n",
        "\n",
        "            if len(autores) >= 3:\n",
        "                resultados.append({\"title\": doc.get(\"title\"), \"authors\": autores})\n",
        "\n",
        "            if len(resultados) == 10:\n",
        "                break\n",
        "\n",
        "        if resultados:\n",
        "            print(\"Artículos en cs.AI o stat.ML con al menos 3 autores:\")\n",
        "            i = 1\n",
        "            for art in resultados:\n",
        "                print(f\"{i}. Título: {art['title']}\")\n",
        "                print(f\"   Autores: {art['authors']}\")\n",
        "                print(\"-\" * 40)\n",
        "                i += 1\n",
        "        else:\n",
        "            print(\"No se encontraron artículos con al menos 3 autores en las categorías dadas.\")\n",
        "\n",
        "        return resultados\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error al buscar artículos: {e}\")\n",
        "        return []\n",
        "\n",
        "# Ejecutar función\n",
        "articulos_encontrados = buscar_articulos_csai_statml_3autores(collection)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Consulta 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Artículos en hep-ph con DOI:\n",
            "\n",
            "1. Título: Calculation of prompt diphoton production cross sections at Tevatron and\n",
            "  LHC energies\n",
            "   Categorías: hep-ph\n",
            "   PDF: https://arxiv.org/pdf/0704.0001\n",
            "----------------------------------------\n",
            "2. Título: Lifetime of doubly charmed baryons\n",
            "   Categorías: hep-ph\n",
            "   PDF: https://arxiv.org/pdf/0704.0016\n",
            "----------------------------------------\n",
            "3. Título: Understanding the Flavor Symmetry Breaking and Nucleon Flavor-Spin\n",
            "  Structure within Chiral Quark Model\n",
            "   Categorías: hep-ph\n",
            "   PDF: https://arxiv.org/pdf/0704.0029\n",
            "----------------------------------------\n",
            "4. Título: Crystal channeling of LHC forward protons with preserved distribution in\n",
            "  phase space\n",
            "   Categorías: hep-ph\n",
            "   PDF: https://arxiv.org/pdf/0704.0031\n",
            "----------------------------------------\n",
            "5. Título: Probing non-standard neutrino interactions with supernova neutrinos\n",
            "   Categorías: hep-ph\n",
            "   PDF: https://arxiv.org/pdf/0704.0032\n",
            "----------------------------------------\n",
            "6. Título: Experimental efforts in search of 76Ge Neutrinoless Double Beta Decay\n",
            "   Categorías: hep-ph\n",
            "   PDF: https://arxiv.org/pdf/0704.0063\n",
            "----------------------------------------\n",
            "7. Título: Towards self-consistent definition of instanton liquid parameters\n",
            "   Categorías: hep-ph\n",
            "   PDF: https://arxiv.org/pdf/0704.0141\n",
            "----------------------------------------\n",
            "8. Título: Instanton Liquid at Finite Temperature and Chemical Potential of Quarks\n",
            "   Categorías: hep-ph\n",
            "   PDF: https://arxiv.org/pdf/0704.0143\n",
            "----------------------------------------\n",
            "9. Título: Low Energy Aspects of Heavy Meson Decays\n",
            "   Categorías: hep-ph\n",
            "   PDF: https://arxiv.org/pdf/0704.0167\n",
            "----------------------------------------\n",
            "10. Título: Very strong and slowly varying magnetic fields as source of axions\n",
            "   Categorías: hep-ph\n",
            "   PDF: https://arxiv.org/pdf/0704.0169\n",
            "----------------------------------------\n",
            "11. Título: Dark energy and neutrino model in SUSY -- Remarks on active and sterile\n",
            "  neutrinos mixing --\n",
            "   Categorías: hep-ph\n",
            "   PDF: https://arxiv.org/pdf/0704.0186\n",
            "----------------------------------------\n",
            "12. Título: Remarks on N_c dependence of decays of exotic baryons\n",
            "   Categorías: hep-ph\n",
            "   PDF: https://arxiv.org/pdf/0704.0196\n",
            "----------------------------------------\n",
            "13. Título: Does the present data on B_s - bar B_s mixing rule out a large\n",
            "  enhancement in the branching ratio of B_s --> mu+ mu- ?\n",
            "   Categorías: hep-ph\n",
            "   PDF: https://arxiv.org/pdf/0704.0252\n",
            "----------------------------------------\n",
            "14. Título: Unravelling the sbottom spin at the CERN LHC\n",
            "   Categorías: hep-ph\n",
            "   PDF: https://arxiv.org/pdf/0704.0254\n",
            "----------------------------------------\n",
            "15. Título: A practical Seedless Infrared-Safe Cone jet algorithm\n",
            "   Categorías: hep-ph\n",
            "   PDF: https://arxiv.org/pdf/0704.0292\n",
            "----------------------------------------\n"
          ]
        }
      ],
      "source": [
        "def leer_hep_ph_con_doi(collection):\n",
        "    try:\n",
        "        cursor = collection.find(\n",
        "            {\"categories\": \"hep-ph\", \"doi\": {\"$exists\": True, \"$ne\": \"\"}},\n",
        "            {\"_id\": 0, \"title\": 1, \"categories\": 1, \"pdf_source\": 1}).limit(15)\n",
        "\n",
        "        resultados = []\n",
        "        for doc in cursor:\n",
        "            resultados.append({\n",
        "                \"titulo\": doc.get(\"title\", \"Sin título\"),\n",
        "                \"categorias\": doc.get(\"categories\", []),\n",
        "                \"pdf_source\": doc.get(\"pdf_source\", \"No disponible\")\n",
        "            })\n",
        "\n",
        "        if resultados:\n",
        "            print(\"Artículos en hep-ph con DOI:\")\n",
        "            print()\n",
        "            i = 1\n",
        "            for art in resultados:\n",
        "                print(f\"{i}. Título: {art['titulo']}\")\n",
        "                print(f\"   Categorías: {art['categorias']}\")\n",
        "                print(f\"   PDF: {art['pdf_source']}\")\n",
        "                print(\"-\" * 40)\n",
        "                i += 1\n",
        "        else:\n",
        "            print(\"No se encontraron artículos en hep-ph con DOI.\")\n",
        "\n",
        "        return resultados\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error al buscar artículos hep-ph con DOI: {e}\")\n",
        "        return []\n",
        "\n",
        "articulos_encontrados = leer_hep_ph_con_doi(collection)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Consulta 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Artículos con DOI:\n",
            "\n",
            "1.Título: !-Graphs with Trivial Overlap are Context-Free\n",
            "  Autores: Aleks Kissinger (University of Oxford), Vladimir Zamdzhiev (University\n",
            "  of Oxford)\n",
            "  Referencia publicación: EPTCS 181, 2015, pp. 16-31\n",
            "----------------------------------------\n",
            "2.Título: !Qu\\'e maravilla! Multimodal Sarcasm Detection in Spanish: a Dataset and\n",
            "  a Baseline\n",
            "  Autores: Khalid Alnajjar and Mika H\\\"am\\\"al\\\"ainen\n",
            "  Referencia publicación: None\n",
            "----------------------------------------\n",
            "3.Título: \"$1k_F$\" Singularities and Finite Density ABJM Theory at Strong Coupling\n",
            "  Autores: Oscar Henriksson and Christopher Rosen\n",
            "  Referencia publicación: None\n",
            "----------------------------------------\n",
            "4.Título: \"$\\mathbf{{\\textit K^-}{\\textit p}{\\textit p}}$\", a\n",
            "  ${\\overline{K}}$-Meson Nuclear Bound State, Observed in $^{3}{\\rm He}({K^-},\n",
            "  {\\Lambda} p)n$ Reactions\n",
            "  Autores: J-PARC E15 collaboration, S. Ajimura, H. Asano, G. Beer, C. Berucci,\n",
            "  H. Bhang, M. Bragadireanu, P. Buehler, L. Busso, M. Cargnelli, S. Choi, C.\n",
            "  Curceanu, S. Enomoto, H. Fujioka, Y. Fujiwara, T. Fukuda, C. Guaraldo, T.\n",
            "  Hashimoto, R. S. Hayano, T. Hiraiwa, M. Iio, M. Iliescu, K. Inoue, Y.\n",
            "  Ishiguro, T. Ishikawa, S. Ishimoto, K. Itahashi, M. Iwasaki, K. Kanno, K.\n",
            "  Kato, Y. Kato, S. Kawasaki, P. Kienle, H. Kou, Y. Ma, J. Marton, Y. Matsuda,\n",
            "  Y. Mizoi, O. Morra, T. Nagae, H. Noumi, H. Ohnishi, S. Okada, H. Outa, K.\n",
            "  Piscicchia, Y. Sada, A. Sakaguchi, F. Sakuma, M. Sato, A. Scordo, M.\n",
            "  Sekimoto, H. Shi, K. Shirotori, D. Sirghi, F. Sirghi, K. Suzuki, S. Suzuki,\n",
            "  T. Suzuki, K. Tanida, H. Tatsuno, M. Tokuda, D. Tomono, A. Toyoda, K.\n",
            "  Tsukada, O. Vazquez Doce, E. Widmann, T. Yamaga, T. Yamazaki, Q. Zhang, and\n",
            "  J. Zmeskal\n",
            "  Referencia publicación: None\n",
            "----------------------------------------\n",
            "5.Título: \"'Formal' vs. 'Empirical' Approaches to Quantum-Classical Reduction\"\n",
            "  Autores: Joshua Rosaler\n",
            "  Referencia publicación: Topoi Volume 34, Issue 2, pp 325-338, 2015\n",
            "----------------------------------------\n",
            "6.Título: \"(Weitergeleitet von Journalistin)\": The Gendered Presentation of\n",
            "  Professions on Wikipedia\n",
            "  Autores: Olga Zagovora (1), Fabian Fl\\\"ock (1), Claudia Wagner (1 and 2) ((1)\n",
            "  GESIS - Leibniz Institute for the Social Sciences, (2) University of\n",
            "  Koblenz-Landau)\n",
            "  Referencia publicación: None\n",
            "----------------------------------------\n",
            "7.Título: \"+-+\" Brane Model Phenomenology\n",
            "  Autores: Stavros Mouslopoulos and Antonios Papazoglou (Oxford University)\n",
            "  Referencia publicación: JHEP 0011 (2000) 018\n",
            "----------------------------------------\n",
            "8.Título: \".. I didn't reflect much on what I was doing..\" How Planck discovered\n",
            "  his radiation formula\n",
            "  Autores: Domenico Giulini and Norbert Straumann (Univ. of Zuerich, Switzerland)\n",
            "  Referencia publicación: None\n",
            "----------------------------------------\n",
            "9.Título: \"0.7 anomaly\" and magnetic impurity formation in quantum point contacts\n",
            "  Autores: S. Ihnatsenka and I. V. Zozoulenko\n",
            "  Referencia publicación: None\n",
            "----------------------------------------\n",
            "10.Título: \"23andMe confirms: I'm super white\" -- Analyzing Twitter Discourse On\n",
            "  Genetic Testing\n",
            "  Autores: Alexandros Mittos, Jeremy Blackburn, Emiliano De Cristofaro\n",
            "  Referencia publicación: None\n",
            "----------------------------------------\n",
            "11.Título: \"420 Friendly\": Revealing Marijuana Use via Craigslist Rental Ads\n",
            "  Autores: Anh Nguyen, Long Nguyen, Dong Nguyen, Uyen Le and Tuan Tran\n",
            "  Referencia publicación: None\n",
            "----------------------------------------\n",
            "12.Título: \"4n multipole periodicity\" of the Galaxy image in the WMAP data\n",
            "  Autores: Pavel D. Naselsky, Igor D. Novikov (NBI)\n",
            "  Referencia publicación: None\n",
            "----------------------------------------\n",
            "13.Título: \"6 choose 4\": A framework to understand and facilitate discussion of\n",
            "  strategies for overall survival safety monitoring\n",
            "  Autores: Godwin Yung, Kaspar Rufibach, Marcel Wolbers, Mark Yan, Jue Wang\n",
            "  Referencia publicación: None\n",
            "----------------------------------------\n",
            "14.Título: \"A Good Bot Always Knows Its Limitations\": Assessing Autonomous System\n",
            "  Decision-making Competencies through Factorized Machine Self-confidence\n",
            "  Autores: Brett W. Israelsen, Nisar R. Ahmed, Matthew Aitken, Eric W. Frew, Dale\n",
            "  A. Lawrence, Brian M. Argrow\n",
            "  Referencia publicación: None\n",
            "----------------------------------------\n",
            "15.Título: \"A Great Start, But...\": Evaluating LLM-Generated Mind Maps for\n",
            "  Information Mapping in Video-Based Design\n",
            "  Autores: Tianhao He, Karthi Saravanan, Evangelos Niforatos, Gerd Kortuem\n",
            "  Referencia publicación: None\n",
            "----------------------------------------\n",
            "16.Título: \"A Handbook of Integer Sequences\" Fifty Years Later\n",
            "  Autores: N. J. A. Sloane\n",
            "  Referencia publicación: None\n",
            "----------------------------------------\n",
            "17.Título: \"A Hint From the Inter-Family Mass Hierarchy: Two Vector-Like Families\n",
            "  in the TeV range\"\n",
            "  Autores: K.S. Babu, Jogesh C. Pati and Hanns Stremnitzer\n",
            "  Referencia publicación: Phys.Rev.D51:2451-2462,1995\n",
            "----------------------------------------\n",
            "18.Título: \"A Little is Enough\": Few-Shot Quality Estimation based Corpus Filtering\n",
            "  improves Machine Translation\n",
            "  Autores: Akshay Batheja, Pushpak Bhattacharyya\n",
            "  Referencia publicación: None\n",
            "----------------------------------------\n",
            "19.Título: \"A Lot of Moving Parts\": A Case Study of Open-Source Hardware Design\n",
            "  Collaboration in the Thingiverse Community\n",
            "  Autores: Kathy Cheng, Shurui Zhou, Alison Olechowski\n",
            "  Referencia publicación: None\n",
            "----------------------------------------\n",
            "20.Título: \"A Nova Eletricidade: Aplica\\c{c}\\~oes, Riscos e Tend\\^encias da IA\n",
            "  Moderna -- \"The New Electricity\": Applications, Risks, and Trends in Current\n",
            "  AI\n",
            "  Autores: Ana L.C. Bazzan, Anderson R. Tavares, Andr\\'e G. Pereira, Cl\\'audio R.\n",
            "  Jung, Jacob Scharcanski, Joel Luis Carbonera, Lu\\'is C. Lamb, Mariana\n",
            "  Recamonde-Mendoza, Thiago L.T. da Silveira, Viviane Moreira\n",
            "  Referencia publicación: None\n",
            "----------------------------------------\n"
          ]
        }
      ],
      "source": [
        "def leer_articulos_con_doi(collection):\n",
        "    \"\"\"\n",
        "    Devuelve títulos, autores y referencia de publicación de artículos con DOI.\n",
        "    Ordena alfabéticamente por título y limita a 20 resultados.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        cursor = collection.find(\n",
        "            {\"doi\": {\"$exists\": True, \"$ne\": \"\"}},\n",
        "            {\"_id\": 0, \"title\": 1, \"authors\": 1, \"journal-ref\": 1}).sort(\"title\", 1).limit(20)\n",
        "\n",
        "        resultados = []\n",
        "        for doc in cursor:\n",
        "            resultados.append({\n",
        "                \"titulo\": doc.get(\"title\", \"Sin título\"),\n",
        "                \"autores\": doc.get(\"authors\", []),\n",
        "                \"referencia_publicacion\": doc.get(\"journal-ref\", \"No disponible\")\n",
        "            })\n",
        "\n",
        "        if resultados:\n",
        "            print(\"Artículos con DOI:\")\n",
        "            print()\n",
        "            i = 1\n",
        "            for art in resultados:\n",
        "                print(f\"{i}.Título: {art['titulo']}\")\n",
        "                print(f\"  Autores: {art['autores']}\")\n",
        "                print(f\"  Referencia publicación: {art['referencia_publicacion']}\")\n",
        "                print(\"-\" * 40)\n",
        "                i += 1\n",
        "        else:\n",
        "            print(\"No se encontraron artículos con DOI.\")\n",
        "\n",
        "        return resultados\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error al buscar artículos con DOI: {e}\")\n",
        "        return []\n",
        "\n",
        "articulos_encontrados = leer_articulos_con_doi(collection)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Consulta 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1. Titulo: A landscape of non-supersymmetric AdS vacua on coset manifolds\n",
            "  Primera versión: Mon, 4 Jan 2010 13:51:46 GMT\n",
            "--------------------------------------------------\n",
            "2. Titulo: Jet Shapes and Jet Algorithms in SCET\n",
            "  Primera versión: Mon, 4 Jan 2010 20:56:57 GMT\n",
            "--------------------------------------------------\n",
            "3. Titulo: A Comprehensive Analysis of Uncertainties Affecting the Stellar Mass -\n",
            "  Halo Mass Relation for 0<z<4\n",
            "  Primera versión: Sun, 3 Jan 2010 19:43:29 GMT\n",
            "--------------------------------------------------\n",
            "4. Titulo: Testing product states, quantum Merlin-Arthur games and tensor\n",
            "  optimisation\n",
            "  Primera versión: Mon, 4 Jan 2010 18:01:41 GMT\n",
            "--------------------------------------------------\n",
            "5. Titulo: Mu-Tau Production at Hadron Colliders\n",
            "  Primera versión: Mon, 4 Jan 2010 04:10:52 GMT\n",
            "--------------------------------------------------\n",
            "6. Titulo: New identities involving q-Euler polynomials of higher order\n",
            "  Primera versión: Mon, 4 Jan 2010 15:34:13 GMT\n",
            "--------------------------------------------------\n",
            "7. Titulo: Strong Constraints to the Putative Planet Candidate around VB 10 using\n",
            "  Doppler spectroscopy\n",
            "  Primera versión: Fri, 1 Jan 2010 00:07:58 GMT\n",
            "--------------------------------------------------\n",
            "8. Titulo: Arrested phase separation in reproducing bacteria: a generic route to\n",
            "  pattern formation?\n",
            "  Primera versión: Mon, 4 Jan 2010 19:56:03 GMT\n",
            "--------------------------------------------------\n",
            "9. Titulo: Euclid Imaging Consortium Science Book\n",
            "  Primera versión: Mon, 4 Jan 2010 15:34:42 GMT\n",
            "--------------------------------------------------\n",
            "10. Titulo: Bayesian Methods and Universal Darwinism\n",
            "  Primera versión: Mon, 4 Jan 2010 17:01:57 GMT\n",
            "--------------------------------------------------\n",
            "11. Titulo: News on PHOTOS Monte Carlo: gamma^* -> pi^+ pi^-(gamma) and K^\\pm ->\n",
            "  pi^+ pi^- e^\\pm nu (gamma)\n",
            "  Primera versión: Mon, 4 Jan 2010 15:50:15 GMT\n",
            "--------------------------------------------------\n",
            "12. Titulo: Nonmeasurability in Banach spaces\n",
            "  Primera versión: Mon, 4 Jan 2010 16:31:26 GMT\n",
            "--------------------------------------------------\n",
            "13. Titulo: Rigid Symmetries and Conservation Laws in Non-Lagrangian Field Theory\n",
            "  Primera versión: Mon, 4 Jan 2010 12:30:50 GMT\n",
            "--------------------------------------------------\n",
            "14. Titulo: The quadratic character of 1+\\sqrt{2} and an elliptic curve\n",
            "  Primera versión: Sun, 3 Jan 2010 04:16:44 GMT\n",
            "--------------------------------------------------\n",
            "15. Titulo: Collapsing and Separating Completeness Notions under Average-Case and\n",
            "  Worst-Case Hypotheses\n",
            "  Primera versión: Mon, 4 Jan 2010 20:55:05 GMT\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "def obtener_articulos_2010_2015(collection):\n",
        "    try:\n",
        "        # Expresión regular para años del 2010 al 2015 en la fecha creada\n",
        "        regex = {\"$regex\": r\"201[0-5]\"}\n",
        "        \n",
        "        # Solo pedimos los artículos con una primera versión que coincida\n",
        "        cursor = collection.find(\n",
        "            { \"versions.0.created\": regex },\n",
        "            { \"title\": 1, \"versions\": 1 }\n",
        "        ).limit(15)\n",
        "\n",
        "        resultados = []\n",
        "        for doc in cursor:\n",
        "            title = doc.get(\"title\", \"(sin título)\")\n",
        "            versiones = doc.get(\"versions\", [])\n",
        "            if versiones and \"created\" in versiones[0]:\n",
        "                fecha = versiones[0][\"created\"]\n",
        "            else:\n",
        "                fecha = \"¿sin fecha?\"\n",
        "                \n",
        "            resultados.append({\n",
        "                \"title\": title,\n",
        "                \"fecha_primera_version\": fecha\n",
        "            })\n",
        "        i = 1\n",
        "        for r in resultados:\n",
        "            print(f\"{i}. Titulo: {r['title']}\")\n",
        "            print(f\"  Primera versión: {r['fecha_primera_version']}\")\n",
        "            print(\"-\" * 50)\n",
        "            i += 1\n",
        "\n",
        "        return resultados\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error ejecutando la consulta: {e}\")\n",
        "\n",
        "articulos_encontrados = obtener_articulos_2010_2015(collection)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Consulta 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1. Título: Computing genus 2 Hilbert-Siegel modular forms over $\\Q(\\sqrt{5})$ via\n",
            "  the Jacquet-Langlands correspondence\n",
            "   Comentarios: 14 pages; title changed; to appear in Experimental Mathematics\n",
            "   Número de reporte: null\n",
            "--------------------------------------------------\n",
            "2. Título: Iterated integral and the loop product\n",
            "   Comentarios: 18 pages, 1 figure\n",
            "   Número de reporte: null\n",
            "--------------------------------------------------\n",
            "3. Título: Bosonic characters of atomic Cooper pairs across resonance\n",
            "   Comentarios: 6 pages, 4 figures, accepted by PRA\n",
            "   Número de reporte: null\n",
            "--------------------------------------------------\n",
            "4. Título: Partial cubes: structures, characterizations, and constructions\n",
            "   Comentarios: 36 pages, 17 figures\n",
            "   Número de reporte: null\n",
            "--------------------------------------------------\n",
            "5. Título: Polymer Quantum Mechanics and its Continuum Limit\n",
            "   Comentarios: 16 pages, no figures. Typos corrected to match published version\n",
            "   Número de reporte: null\n",
            "--------------------------------------------------\n",
            "6. Título: A determinant of Stirling cycle numbers counts unlabeled acyclic\n",
            "  single-source automata\n",
            "   Comentarios: 11 pages\n",
            "   Número de reporte: null\n",
            "--------------------------------------------------\n",
            "7. Título: Sparsity-certifying Graph Decompositions\n",
            "   Comentarios: To appear in Graphs and Combinatorics\n",
            "   Número de reporte: null\n",
            "--------------------------------------------------\n",
            "8. Título: Calculation of prompt diphoton production cross sections at Tevatron and\n",
            "  LHC energies\n",
            "   Comentarios: 37 pages, 15 figures; published version\n",
            "   Número de reporte: null\n",
            "--------------------------------------------------\n",
            "9. Título: The evolution of the Earth-Moon system based on the dark matter field\n",
            "  fluid model\n",
            "   Comentarios: 23 pages, 3 figures\n",
            "   Número de reporte: null\n",
            "--------------------------------------------------\n",
            "10. Título: Numerical solution of shock and ramp compression for general material\n",
            "  properties\n",
            "   Comentarios: Minor corrections\n",
            "   Número de reporte: null\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "def obtener_articulos_no_nulos(collection):\n",
        "    try:\n",
        "        cursor = collection.find(\n",
        "            # Filtro para artículos que tienen comentarios no nulos.\n",
        "            {\"comments\": {\"$exists\": True, \"$ne\": None}},\n",
        "            # Buscamos solo por titulo, comentarios y número de reporte.\n",
        "            {\"title\": 1, \"comments\": 1, \"report-no\": 1}\n",
        "        ).sort(\"updated\", -1).limit(10)\n",
        "\n",
        "        resultados = []\n",
        "        for doc in cursor:\n",
        "            resultados.append({\n",
        "                \"title\": doc.get(\"title\", \"Sin título\"),\n",
        "                \"comments\": doc.get(\"comments\", []),\n",
        "                \"report_no\": doc.get(\"doi\", {}).get(\"report-no\", \"null\")\n",
        "            })\n",
        "        \n",
        "        return resultados\n",
        "    \n",
        "    except Exception as e:\n",
        "        print(f\"Error ejecutando la consulta: {e}\")\n",
        "\n",
        "articulos_encontrados = obtener_articulos_no_nulos(collection)\n",
        "i = 1\n",
        "for articulos in articulos_encontrados:\n",
        "    print(f\"{i}. Título: {articulos['title']}\")\n",
        "    print(f\"   Comentarios: {articulos['comments']}\")\n",
        "    print(f\"   Número de reporte: {articulos['report_no']}\")\n",
        "    print(\"-\" * 50)\n",
        "    i += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Código para asegurar consistencia de los datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Insertamos un dato \"test\" en el contenedor principal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Documento insertado en mongo1 con ID: 6848f0fed20bc43658f8e8c9\n"
          ]
        }
      ],
      "source": [
        "#Con el siguiente código insertamos un documento de prueba en el nodo primario\n",
        "def insertar_en_nodoPrimario(collection, data):\n",
        "    try:\n",
        "        result = collection.insert_one(data)\n",
        "        print(f\"Documento insertado en mongo1 con ID: {result.inserted_id}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error al insertar en mongo1: {e}\")\n",
        "\n",
        "insertar_en_nodoPrimario(collection, {\"test\": \"replicacion_OK\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ahora, consultamos en los tres contenedores si se encuentra el dato \"test\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Dato encontrado en mongo1: {'_id': ObjectId('6848f0fed20bc43658f8e8c9'), 'test': 'replicacion_OK'}\n",
            "✅ Dato encontrado en mongo2: {'_id': ObjectId('6848f0fed20bc43658f8e8c9'), 'test': 'replicacion_OK'}\n",
            "✅ Dato encontrado en mongo3: {'_id': ObjectId('6848f0fed20bc43658f8e8c9'), 'test': 'replicacion_OK'}\n"
          ]
        }
      ],
      "source": [
        "#Ahora buscamos el dato insertado en cada nodo del Replica Set\n",
        "def buscar_dato_test_por_nodo(port, contenedor):\n",
        "    try:\n",
        "        client = MongoClient(f\"mongodb://localhost:{port}\", serverSelectionTimeoutMS=5000)\n",
        "        db = client[\"arxiv_db\"]\n",
        "        collection = db[\"articles\"]\n",
        "\n",
        "        result = collection.find_one({\"test\": \"replicacion_OK\"})\n",
        "        if result:\n",
        "            print(f\"-> Dato encontrado en {contenedor}: {result}\")\n",
        "        else:\n",
        "            print(f\"-> Dato no encontrado en {contenedor}.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error al buscar en {contenedor}: {e}\")\n",
        "\n",
        "#Llamamos por cada nodo si existe el dato insertado\n",
        "buscar_dato_test_por_nodo(27017, \"mongo1\")\n",
        "buscar_dato_test_por_nodo(27018, \"mongo2\")\n",
        "buscar_dato_test_por_nodo(27019, \"mongo3\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "En el siguiente paso, actualizamos el dato en el nodo principal y verificamos la replicación en los otros nodos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No se encontró el dato para actualizar.\n",
            "--------------------------------------------------\n",
            "Dato encontrado en mongo1: {'_id': ObjectId('6848f0fed20bc43658f8e8c9'), 'test': 'Actualizado!'}\n",
            "Dato encontrado en mongo2: {'_id': ObjectId('6848f0fed20bc43658f8e8c9'), 'test': 'Actualizado!'}\n",
            "Dato encontrado en mongo3: {'_id': ObjectId('6848f0fed20bc43658f8e8c9'), 'test': 'Actualizado!'}\n"
          ]
        }
      ],
      "source": [
        "def actualizar_dato_test():\n",
        "    try:\n",
        "        # Actualizamos el campo \"test\" a \"Actualizado!\" en el nodo primario\n",
        "        result = collection.update_one(\n",
        "            {\"test\": \"replicacion_OK\"},\n",
        "            {\"$set\": {\"test\": \"Actualizado!\"}}\n",
        "        )\n",
        "        if result.modified_count > 0:\n",
        "            print(\"-> Dato actualizado correctamente.\")\n",
        "        else:\n",
        "            print(\"-> No se encontró el dato para actualizar.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error al actualizar el dato: {e}\")\n",
        "\n",
        "def buscar_dato_test_por_nodo(port, contenedor):\n",
        "    try:\n",
        "        client = MongoClient(f\"mongodb://localhost:{port}\", serverSelectionTimeoutMS=5000)\n",
        "        db = client[\"arxiv_db\"]\n",
        "        collection = db[\"articles\"]\n",
        "\n",
        "        result = collection.find_one({\"test\": \"Actualizado!\"})\n",
        "        if result:\n",
        "            print(f\"-> Dato encontrado en {contenedor}: {result}\")\n",
        "        else:\n",
        "            print(f\"-> Dato no encontrado en {contenedor}.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error al buscar en {contenedor}: {e}\")\n",
        "\n",
        "actualizar_dato_test()\n",
        "print(\"-\"*50)\n",
        "buscar_dato_test_por_nodo(27017, \"mongo1\")\n",
        "buscar_dato_test_por_nodo(27018, \"mongo2\")\n",
        "buscar_dato_test_por_nodo(27019, \"mongo3\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ahora borramos el dato que hemos actualizado y lo buscamos en los 3 contenedores para verificar efectivamente la consistencia de los datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-> Dato borrado correctamente.\n",
            "--------------------------------------------------\n",
            "-> Dato no encontrado en mongo1.\n",
            "-> Dato no encontrado en mongo2.\n",
            "-> Dato no encontrado en mongo3.\n"
          ]
        }
      ],
      "source": [
        "def borrar_dato_test():\n",
        "    try:\n",
        "        result = collection.delete_one({\"test\": \"Actualizado!\"})\n",
        "        if result.deleted_count > 0:\n",
        "            print(\"-> Dato borrado correctamente.\")\n",
        "        else:\n",
        "            print(\"-> No se encontró el dato para borrar.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error al borrar el dato: {e}\")\n",
        "\n",
        "def buscar_dato_test_por_nodo(port, contenedor):\n",
        "    try:\n",
        "        client = MongoClient(f\"mongodb://localhost:{port}\", serverSelectionTimeoutMS=5000)\n",
        "        db = client[\"arxiv_db\"]\n",
        "        collection = db[\"articles\"]\n",
        "\n",
        "        result = collection.find_one({\"test\": \"Actualizado!\"})\n",
        "        if result:\n",
        "            print(f\"-> Dato encontrado en {contenedor}: {result}\")\n",
        "        else:\n",
        "            print(f\"-> Dato no encontrado en {contenedor}.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error al buscar en {contenedor}: {e}\")\n",
        "\n",
        "borrar_dato_test()\n",
        "print(\"-\"*50)\n",
        "buscar_dato_test_por_nodo(27017, \"mongo1\")\n",
        "buscar_dato_test_por_nodo(27018, \"mongo2\")\n",
        "buscar_dato_test_por_nodo(27019, \"mongo3\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
