{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Tarea 3 MongoDB, arXiv\n",
        "##### Integrantes:\n",
        "Bruno Morici, ROL: 202373555-8,\n",
        "Martin Aranda, ROL: 202373021-1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLP_JWcpkpxb"
      },
      "source": [
        "## Primera Etapa\n",
        "Instalaci√≥n de dependencias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjQ3LC2IKV5T",
        "outputId": "49b89894-2894-495c-8130-73fbc4804ab7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pymongo in c:\\users\\bruno\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.13.0)\n",
            "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in c:\\users\\bruno\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pymongo) (2.7.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.3.1 -> 25.1.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tqdm in c:\\users\\bruno\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.67.1)\n",
            "Requirement already satisfied: colorama in c:\\users\\bruno\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm) (0.4.6)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.3.1 -> 25.1.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "# Instalamos dependencias\n",
        "!pip install pymongo\n",
        "!pip install tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Segunda Etapa\n",
        "Conexi√≥n a la BD \"arxiv_db\" y creaci√≥n de colecci√≥n \"articles\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Conexi√≥n exitosa\n",
            "Primario: ('mongo1', 27017)\n"
          ]
        }
      ],
      "source": [
        "from pymongo import MongoClient\n",
        "\n",
        "# Conexi√≥n a Replica Set con preferencia al primario\n",
        "client = MongoClient(\"mongodb://mongo1:27017,mongo2:27017,mongo3:27017/?replicaSet=rs0\")\n",
        "\n",
        "db = client[\"arxiv_db\"]\n",
        "collection = db[\"articles\"]\n",
        "\n",
        "try:\n",
        "    server_info = client.server_info()\n",
        "    print(\"‚úÖ Conexi√≥n exitosa\")\n",
        "    print(f\"Primario: {client.primary}\") # El cliente retorna un primario mal detectado, es normal, pero las escrituras se realizan sobre mongo1\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error de conexi√≥n: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Tercera Etapa\n",
        "Procesamiento del dataset hacia la BD (ejecutar una sola vez, luego los datos quedan en la BD)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Observaci√≥n: El dataset tiene un JSON en cada l√≠nea, no es una lista de JSON's. Recorremos cada JSON, lo parseamos y guardamos en una lista de data (demora unos 6 minutos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "GU00dCWikwRA",
        "outputId": "7a5a8ae0-4d89-4ede-9fe9-3383a567aca6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iniciando carga de datos a MongoDB...\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 39\u001b[39m\n\u001b[32m     35\u001b[39m             total_docs += \u001b[38;5;28mlen\u001b[39m(batch)\n\u001b[32m     37\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mTotal de documentos insertados: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_docs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m \u001b[43mload_data_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Llamamos la funcion creada anteriormente\u001b[39;00m\n\u001b[32m     41\u001b[39m \u001b[38;5;66;03m# 3. Verificacion final\u001b[39;00m\n\u001b[32m     42\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mResumen de la base de datos:\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 14\u001b[39m, in \u001b[36mload_data_batch\u001b[39m\u001b[34m(batch_size)\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Primero contamos las lineas para la barra de progreso\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[33m'\u001b[39m\u001b[33marxiv-metadata-oai-snapshot.json\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m, encoding=\u001b[33m'\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m     total_lines = \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# Insertamos los datos en el batch\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[33m'\u001b[39m\u001b[33marxiv-metadata-oai-snapshot.json\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m, encoding=\u001b[33m'\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 14\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Primero contamos las lineas para la barra de progreso\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[33m'\u001b[39m\u001b[33marxiv-metadata-oai-snapshot.json\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m, encoding=\u001b[33m'\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m     total_lines = \u001b[38;5;28msum\u001b[39m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# Insertamos los datos en el batch\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[33m'\u001b[39m\u001b[33marxiv-metadata-oai-snapshot.json\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m, encoding=\u001b[33m'\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m<frozen codecs>:319\u001b[39m, in \u001b[36mdecode\u001b[39m\u001b[34m(self, input, final)\u001b[39m\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "import json\n",
        "from tqdm import tqdm # Para mostrar una barra de progreso\n",
        "\n",
        "# Cargar y procesar el archivo JSON\n",
        "print(\"Iniciando carga de datos a MongoDB...\")\n",
        "\n",
        "# Carga por lotes de 1000 en 1000\n",
        "def load_data_batch(batch_size=1000):\n",
        "    batch = []\n",
        "    total_docs = 0\n",
        "    \n",
        "    # Primero contamos las lineas para la barra de progreso\n",
        "    with open('arxiv-metadata-oai-snapshot.json', 'r', encoding='utf-8') as f:\n",
        "        total_lines = sum(1 for _ in f)\n",
        "    \n",
        "    # Insertamos los datos en el batch\n",
        "    with open('arxiv-metadata-oai-snapshot.json', 'r', encoding='utf-8') as f:\n",
        "        for line in tqdm(f, total=total_lines, desc=\"Cargando datos\"):\n",
        "            record = json.loads(line)\n",
        "            # Agregamos el campo pdf_source\n",
        "            if \"id\" in record:\n",
        "                record[\"pdf_source\"] = f\"https://arxiv.org/pdf/{record['id']}\"\n",
        "\n",
        "            batch.append(record)\n",
        "            \n",
        "            # Si el batch excede el maximo, lo vaciamos e insertamos los datos en la BD\n",
        "            if len(batch) >= batch_size:\n",
        "                collection.insert_many(batch)\n",
        "                total_docs += len(batch)\n",
        "                batch = []\n",
        "        \n",
        "        # Insertar el ultimo lote, en caso de que el ultimo lote sean menos de 1000\n",
        "        if batch:\n",
        "            collection.insert_many(batch)\n",
        "            total_docs += len(batch)\n",
        "    \n",
        "    print(f\"\\nTotal de documentos insertados: {total_docs}\")\n",
        "\n",
        "load_data_batch() # Llamamos la funcion creada anteriormente\n",
        "\n",
        "# 3. Verificacion final\n",
        "print(\"\\nResumen de la base de datos:\")\n",
        "print(f\"- Colecci√≥n: {collection.name}\")    \n",
        "print(f\"- Ejemplo de documento: {collection.find_one()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üì¶ Documentos estimados en mongo1: 2744489\n",
            "üì¶ Documentos estimados en mongo2: 2744489\n",
            "üì¶ Documentos estimados en mongo3: 2744489\n"
          ]
        }
      ],
      "source": [
        "ports = [27017, 27018, 27019]\n",
        "for i, port in enumerate(ports, start=1):\n",
        "    client = MongoClient(f\"mongodb://localhost:{port}\")\n",
        "    count = client[\"arxiv_db\"][\"articles\"].estimated_document_count()\n",
        "    print(f\"üì¶ Documentos estimados en mongo{i}: {count}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cuarta etapa: Consultas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Consulta test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üü¢ mongo1 (27017) - Art√≠culos con 'Software':\n",
            "   üîπ Solar Magnetic Tracking. I. Software Comparison and Recommended\n",
            "  Practices\n",
            "   üîπ On How Developers Test Open Source Software Systems\n",
            "   üîπ Experiences of Engineering Grid-Based Medical Software\n",
            "--------------------------------------------------\n",
            "üü¢ mongo2 (27018) - Art√≠culos con 'Software':\n",
            "   üîπ Solar Magnetic Tracking. I. Software Comparison and Recommended\n",
            "  Practices\n",
            "   üîπ On How Developers Test Open Source Software Systems\n",
            "   üîπ Experiences of Engineering Grid-Based Medical Software\n",
            "--------------------------------------------------\n",
            "üü¢ mongo3 (27019) - Art√≠culos con 'Software':\n",
            "   üîπ Solar Magnetic Tracking. I. Software Comparison and Recommended\n",
            "  Practices\n",
            "   üîπ On How Developers Test Open Source Software Systems\n",
            "   üîπ Experiences of Engineering Grid-Based Medical Software\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "def buscar_software(port, nombre):\n",
        "    try:\n",
        "        client = MongoClient(f\"mongodb://localhost:{port}\", serverSelectionTimeoutMS=5000)\n",
        "        db = client[\"arxiv_db\"]\n",
        "        collection = db[\"articles\"]\n",
        "\n",
        "        resultados = collection.find(\n",
        "            {\"title\": {\"$regex\": \"Software\", \"$options\": \"i\"}},\n",
        "            {\"_id\": 0, \"title\": 1}\n",
        "        ).limit(3)  # solo para mostrar pocos\n",
        "\n",
        "        print(f\"üü¢ {nombre} ({port}) - Art√≠culos con 'Software':\")\n",
        "        encontrados = False\n",
        "        for doc in resultados:\n",
        "            print(f\"   üîπ {doc['title']}\")\n",
        "            encontrados = True\n",
        "        if not encontrados:\n",
        "            print(\"   ‚ö†Ô∏è No se encontraron art√≠culos.\")\n",
        "        print(\"-\" * 50)\n",
        "    except Exception as e:\n",
        "        print(f\"üî¥ Error en {nombre} ({port}): {e}\")\n",
        "\n",
        "# Ejecutar b√∫squeda en los tres nodos\n",
        "buscar_software(27017, \"mongo1\")\n",
        "buscar_software(27018, \"mongo2\")\n",
        "buscar_software(27019, \"mongo3\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Consulta 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1. T√≠tulo: IGC: Integrating a Gated Calculator into an LLM to Solve Arithmetic\n",
            "  Tasks Reliably and Efficiently\n",
            "Primera versi√≥n (v1): Wed, 1 Jan 2025 00:01:27 GMT\n",
            "--------------------------------------------------\n",
            "2. T√≠tulo: A quantization of coarse spaces and uniform Roe algebras\n",
            "Primera versi√≥n (v1): Wed, 1 Jan 2025 00:04:43 GMT\n",
            "--------------------------------------------------\n",
            "3. T√≠tulo: NIOS II Soft-Core Processor and Ethernet Controller Solution for RPC-DAQ\n",
            "  in INO ICAL\n",
            "Primera versi√≥n (v1): Wed, 1 Jan 2025 00:37:15 GMT\n",
            "--------------------------------------------------\n",
            "4. T√≠tulo: Minkowski problem of anisotropic p-torsional rigidity\n",
            "Primera versi√≥n (v1): Wed, 1 Jan 2025 00:38:34 GMT\n",
            "--------------------------------------------------\n",
            "5. T√≠tulo: Gravitational Instantons, old and new\n",
            "Primera versi√≥n (v1): Wed, 1 Jan 2025 00:38:55 GMT\n",
            "--------------------------------------------------\n",
            "6. T√≠tulo: Finite groups with exactly two nonlinear irreducible $p$-Brauer\n",
            "  characters\n",
            "Primera versi√≥n (v1): Wed, 1 Jan 2025 00:56:25 GMT\n",
            "--------------------------------------------------\n",
            "7. T√≠tulo: Enhanced Dissipation, Taylor Dispersion, and Inviscid Damping of Couette\n",
            "  flow in the Boussinesq system on the Plane\n",
            "Primera versi√≥n (v1): Wed, 1 Jan 2025 00:57:34 GMT\n",
            "--------------------------------------------------\n",
            "8. T√≠tulo: Labels Generated by Large Language Model Helps Measuring People's\n",
            "  Empathy in Vitro\n",
            "Primera versi√≥n (v1): Wed, 1 Jan 2025 01:06:58 GMT\n",
            "--------------------------------------------------\n",
            "9. T√≠tulo: Adjoint sharding for very long context training of state space models\n",
            "Primera versi√≥n (v1): Wed, 1 Jan 2025 01:10:59 GMT\n",
            "--------------------------------------------------\n",
            "10. T√≠tulo: Beyond Model Scale Limits: End-Edge-Cloud Federated Learning with\n",
            "  Self-Rectified Knowledge Agglomeration\n",
            "Primera versi√≥n (v1): Wed, 1 Jan 2025 01:11:16 GMT\n",
            "--------------------------------------------------\n",
            "11. T√≠tulo: Cosymplectic Lagrangian-like submanifolds\n",
            "Primera versi√≥n (v1): Wed, 1 Jan 2025 01:14:16 GMT\n",
            "--------------------------------------------------\n",
            "12. T√≠tulo: Theory and Applications of Kernel Stein Discrepancy on Riemannian\n",
            "  Manifolds\n",
            "Primera versi√≥n (v1): Wed, 1 Jan 2025 01:21:38 GMT\n",
            "--------------------------------------------------\n",
            "13. T√≠tulo: Cost and Reward Infused Metric Elicitation\n",
            "Primera versi√≥n (v1): Wed, 1 Jan 2025 01:36:49 GMT\n",
            "--------------------------------------------------\n",
            "14. T√≠tulo: PANDA -- Paired Anti-hate Narratives Dataset from Asia: Using an\n",
            "  LLM-as-a-Judge to Create the First Chinese Counterspeech Dataset\n",
            "Primera versi√≥n (v1): Wed, 1 Jan 2025 01:56:32 GMT\n",
            "--------------------------------------------------\n",
            "15. T√≠tulo: A Ritz variational principle for local collisionless gyrokinetic\n",
            "  instabilities\n",
            "Primera versi√≥n (v1): Wed, 1 Jan 2025 02:15:18 GMT\n",
            "--------------------------------------------------\n",
            "16. T√≠tulo: Unconventional Coherence Peak in Cuprate Superconductors\n",
            "Primera versi√≥n (v1): Wed, 1 Jan 2025 02:17:21 GMT\n",
            "--------------------------------------------------\n",
            "17. T√≠tulo: Knowledge-Guided Prompt Learning for Deepfake Facial Image Detection\n",
            "Primera versi√≥n (v1): Wed, 1 Jan 2025 02:18:18 GMT\n",
            "--------------------------------------------------\n",
            "18. T√≠tulo: ResKoopNet: Learning Koopman Representations for Complex Dynamics with\n",
            "  Spectral Residuals\n",
            "Primera versi√≥n (v1): Wed, 1 Jan 2025 02:19:42 GMT\n",
            "--------------------------------------------------\n",
            "19. T√≠tulo: Trading linearity for ellipticity: a nonsmooth approach to Einstein's\n",
            "  theory of gravity and the Lorentzian splitting theorems\n",
            "Primera versi√≥n (v1): Wed, 1 Jan 2025 02:24:51 GMT\n",
            "--------------------------------------------------\n",
            "20. T√≠tulo: Information geometry for types in the large-$n$ limit of random matrices\n",
            "Primera versi√≥n (v1): Wed, 1 Jan 2025 02:27:03 GMT\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def leer_articulos_2025(collection):\n",
        "    try:\n",
        "        # Defino lo que queremos buscar en base a la filtro del a√±o 2025\n",
        "        cursor = collection.find(\n",
        "            {\"versions.0.created\": {\"$regex\": r\"2025\"}},\n",
        "            {\"title\": 1, \"versions\": 1}).limit(20)\n",
        "        \n",
        "        art = []\n",
        "\n",
        "        # Agregamos todo lo recolectado en una lista\n",
        "        for doc in cursor:\n",
        "            art.append({\n",
        "                \"title\": doc.get(\"title\", \"No title\"),\n",
        "                \"versions\": doc.get(\"versions\", [])\n",
        "            })\n",
        "        \n",
        "        return art\n",
        "    except Exception as e:\n",
        "        print(f\"Error al leer art√≠culos de 2025: {e}\")\n",
        "        return []\n",
        "    \n",
        "resultado = leer_articulos_2025(collection)\n",
        "i = 1\n",
        "for elem in resultado:\n",
        "    print(f\"{i}. T√≠tulo: {elem.get('title', '(sin t√≠tulo)')}\")\n",
        "    primera_version = elem.get('versions', [{}])[0]\n",
        "    fecha = primera_version.get('created', '¬øsin fecha?')\n",
        "    print(f\"   Primera versi√≥n (v1): {fecha}\")\n",
        "    print(\"-\" * 50)\n",
        "    i += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Consulta 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Art√≠culos en cs.AI o stat.ML con al menos 3 autores:\n",
            "1. T√≠tulo: Calculating Valid Domains for BDD-Based Interactive Configuration\n",
            "   Autores: ['Tarik Hadzic', 'Rune Moller Jensen', 'Henrik Reif Andersen']\n",
            "----------------------------------------\n",
            "2. T√≠tulo: Personalizing Image Search Results on Flickr\n",
            "   Autores: ['Kristina Lerman', 'Anon Plangprasopchok', 'Chio Wong']\n",
            "----------------------------------------\n",
            "3. T√≠tulo: Unicast and Multicast Qos Routing with Soft Constraint Logic Programming\n",
            "   Autores: ['Stefano Bistarelli', 'Ugo Montanari', 'Francesca Rossi', 'Francesco Santini']\n",
            "----------------------------------------\n",
            "4. T√≠tulo: A study of structural properties on profiles HMMs\n",
            "   Autores: ['Juliana S Bernardes', 'Alberto Davila', 'Vitor Santos Costa', 'Gerson\\n  Zaverucha']\n",
            "----------------------------------------\n",
            "5. T√≠tulo: Introduction to Arabic Speech Recognition Using CMUSphinx System\n",
            "   Autores: ['H. Satori', 'M. Harti', 'N. Chenfour']\n",
            "----------------------------------------\n",
            "6. T√≠tulo: Arabic Speech Recognition System using CMU-Sphinx4\n",
            "   Autores: ['H. Satori', 'M. Harti', 'N. Chenfour']\n",
            "----------------------------------------\n",
            "7. T√≠tulo: Experimenting with recursive queries in database and logic programming\n",
            "  systems\n",
            "   Autores: ['Giorgio Terracina', 'Nicola Leone', 'Vincenzino Lio', 'Claudio Panetta']\n",
            "----------------------------------------\n",
            "8. T√≠tulo: An Adaptive Strategy for the Classification of G-Protein Coupled\n",
            "  Receptors\n",
            "   Autores: ['S. Mohamed', 'D. Rubin', 'and T. Marwala']\n",
            "----------------------------------------\n",
            "9. T√≠tulo: Comparing Robustness of Pairwise and Multiclass Neural-Network Systems\n",
            "  for Face Recognition\n",
            "   Autores: ['J. Uglov', 'V. Schetinin', 'C. Maple']\n",
            "----------------------------------------\n",
            "10. T√≠tulo: Ensemble Learning for Free with Evolutionary Algorithms ?\n",
            "   Autores: [\"Christian Gagn\\\\'e (INFORMATIQUE WGZ INC.)\", 'Mich\\\\`ele Sebag (INRIA\\n  Futurs)', 'Marc Schoenauer (INRIA Futurs)', 'Marco Tomassini (ISI)']\n",
            "----------------------------------------\n"
          ]
        }
      ],
      "source": [
        "def buscar_articulos_csai_statml_3autores(collection):\n",
        "    try:\n",
        "        cursor = collection.find(\n",
        "            {\n",
        "                \"$or\": [\n",
        "                    {\"categories\": {\"$regex\": r\"cs\\.AI\"}},\n",
        "                    {\"categories\": {\"$regex\": r\"stat\\.ML\"}}\n",
        "                ]\n",
        "            },\n",
        "            {\"_id\": 0, \"title\": 1, \"authors\": 1}\n",
        "        ).limit(100)  # buscamos m√°s para filtrar en Python\n",
        "\n",
        "        resultados = []\n",
        "\n",
        "        for doc in cursor:\n",
        "            authors_str = doc.get(\"authors\", \"\")\n",
        "            # separar autores por coma o \"and\"\n",
        "            autores = []\n",
        "            if authors_str:\n",
        "                # primero separar por comas\n",
        "                partes = [a.strip() for a in authors_str.split(\",\")]\n",
        "                # cada parte puede contener 'and', dividirlas tambi√©n\n",
        "                for parte in partes:\n",
        "                    autores.extend([x.strip() for x in parte.split(\" and \") if x.strip() != \"\"])\n",
        "\n",
        "            if len(autores) >= 3:\n",
        "                resultados.append({\"title\": doc.get(\"title\"), \"authors\": autores})\n",
        "\n",
        "            if len(resultados) == 10:\n",
        "                break\n",
        "\n",
        "        if resultados:\n",
        "            print(\"Art√≠culos en cs.AI o stat.ML con al menos 3 autores:\")\n",
        "            i = 1\n",
        "            for art in resultados:\n",
        "                print(f\"{i}. T√≠tulo: {art['title']}\")\n",
        "                print(f\"   Autores: {art['authors']}\")\n",
        "                print(\"-\" * 40)\n",
        "                i += 1\n",
        "        else:\n",
        "            print(\"No se encontraron art√≠culos con al menos 3 autores en las categor√≠as dadas.\")\n",
        "\n",
        "        return resultados\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error al buscar art√≠culos: {e}\")\n",
        "        return []\n",
        "\n",
        "# Ejecutar funci√≥n\n",
        "articulos_encontrados = buscar_articulos_csai_statml_3autores(collection)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Consulta 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Art√≠culos en hep-ph con DOI:\n",
            "\n",
            "1. T√≠tulo: Calculation of prompt diphoton production cross sections at Tevatron and\n",
            "  LHC energies\n",
            "   Categor√≠as: hep-ph\n",
            "   PDF: https://arxiv.org/pdf/0704.0001\n",
            "----------------------------------------\n",
            "2. T√≠tulo: Lifetime of doubly charmed baryons\n",
            "   Categor√≠as: hep-ph\n",
            "   PDF: https://arxiv.org/pdf/0704.0016\n",
            "----------------------------------------\n",
            "3. T√≠tulo: Understanding the Flavor Symmetry Breaking and Nucleon Flavor-Spin\n",
            "  Structure within Chiral Quark Model\n",
            "   Categor√≠as: hep-ph\n",
            "   PDF: https://arxiv.org/pdf/0704.0029\n",
            "----------------------------------------\n",
            "4. T√≠tulo: Crystal channeling of LHC forward protons with preserved distribution in\n",
            "  phase space\n",
            "   Categor√≠as: hep-ph\n",
            "   PDF: https://arxiv.org/pdf/0704.0031\n",
            "----------------------------------------\n",
            "5. T√≠tulo: Probing non-standard neutrino interactions with supernova neutrinos\n",
            "   Categor√≠as: hep-ph\n",
            "   PDF: https://arxiv.org/pdf/0704.0032\n",
            "----------------------------------------\n",
            "6. T√≠tulo: Experimental efforts in search of 76Ge Neutrinoless Double Beta Decay\n",
            "   Categor√≠as: hep-ph\n",
            "   PDF: https://arxiv.org/pdf/0704.0063\n",
            "----------------------------------------\n",
            "7. T√≠tulo: Towards self-consistent definition of instanton liquid parameters\n",
            "   Categor√≠as: hep-ph\n",
            "   PDF: https://arxiv.org/pdf/0704.0141\n",
            "----------------------------------------\n",
            "8. T√≠tulo: Instanton Liquid at Finite Temperature and Chemical Potential of Quarks\n",
            "   Categor√≠as: hep-ph\n",
            "   PDF: https://arxiv.org/pdf/0704.0143\n",
            "----------------------------------------\n",
            "9. T√≠tulo: Low Energy Aspects of Heavy Meson Decays\n",
            "   Categor√≠as: hep-ph\n",
            "   PDF: https://arxiv.org/pdf/0704.0167\n",
            "----------------------------------------\n",
            "10. T√≠tulo: Very strong and slowly varying magnetic fields as source of axions\n",
            "   Categor√≠as: hep-ph\n",
            "   PDF: https://arxiv.org/pdf/0704.0169\n",
            "----------------------------------------\n",
            "11. T√≠tulo: Dark energy and neutrino model in SUSY -- Remarks on active and sterile\n",
            "  neutrinos mixing --\n",
            "   Categor√≠as: hep-ph\n",
            "   PDF: https://arxiv.org/pdf/0704.0186\n",
            "----------------------------------------\n",
            "12. T√≠tulo: Remarks on N_c dependence of decays of exotic baryons\n",
            "   Categor√≠as: hep-ph\n",
            "   PDF: https://arxiv.org/pdf/0704.0196\n",
            "----------------------------------------\n",
            "13. T√≠tulo: Does the present data on B_s - bar B_s mixing rule out a large\n",
            "  enhancement in the branching ratio of B_s --> mu+ mu- ?\n",
            "   Categor√≠as: hep-ph\n",
            "   PDF: https://arxiv.org/pdf/0704.0252\n",
            "----------------------------------------\n",
            "14. T√≠tulo: Unravelling the sbottom spin at the CERN LHC\n",
            "   Categor√≠as: hep-ph\n",
            "   PDF: https://arxiv.org/pdf/0704.0254\n",
            "----------------------------------------\n",
            "15. T√≠tulo: A practical Seedless Infrared-Safe Cone jet algorithm\n",
            "   Categor√≠as: hep-ph\n",
            "   PDF: https://arxiv.org/pdf/0704.0292\n",
            "----------------------------------------\n"
          ]
        }
      ],
      "source": [
        "def leer_hep_ph_con_doi(collection):\n",
        "    try:\n",
        "        cursor = collection.find(\n",
        "            {\"categories\": \"hep-ph\", \"doi\": {\"$exists\": True, \"$ne\": \"\"}},\n",
        "            {\"_id\": 0, \"title\": 1, \"categories\": 1, \"pdf_source\": 1}).limit(15)\n",
        "\n",
        "        resultados = []\n",
        "        for doc in cursor:\n",
        "            resultados.append({\n",
        "                \"titulo\": doc.get(\"title\", \"Sin t√≠tulo\"),\n",
        "                \"categorias\": doc.get(\"categories\", []),\n",
        "                \"pdf_source\": doc.get(\"pdf_source\", \"No disponible\")\n",
        "            })\n",
        "\n",
        "        if resultados:\n",
        "            print(\"Art√≠culos en hep-ph con DOI:\")\n",
        "            print()\n",
        "            i = 1\n",
        "            for art in resultados:\n",
        "                print(f\"{i}. T√≠tulo: {art['titulo']}\")\n",
        "                print(f\"   Categor√≠as: {art['categorias']}\")\n",
        "                print(f\"   PDF: {art['pdf_source']}\")\n",
        "                print(\"-\" * 40)\n",
        "                i += 1\n",
        "        else:\n",
        "            print(\"No se encontraron art√≠culos en hep-ph con DOI.\")\n",
        "\n",
        "        return resultados\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error al buscar art√≠culos hep-ph con DOI: {e}\")\n",
        "        return []\n",
        "\n",
        "articulos_encontrados = leer_hep_ph_con_doi(collection)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Consulta 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Art√≠culos con DOI:\n",
            "\n",
            "1.T√≠tulo: !-Graphs with Trivial Overlap are Context-Free\n",
            "  Autores: Aleks Kissinger (University of Oxford), Vladimir Zamdzhiev (University\n",
            "  of Oxford)\n",
            "  Referencia publicaci√≥n: EPTCS 181, 2015, pp. 16-31\n",
            "----------------------------------------\n",
            "2.T√≠tulo: !Qu\\'e maravilla! Multimodal Sarcasm Detection in Spanish: a Dataset and\n",
            "  a Baseline\n",
            "  Autores: Khalid Alnajjar and Mika H\\\"am\\\"al\\\"ainen\n",
            "  Referencia publicaci√≥n: None\n",
            "----------------------------------------\n",
            "3.T√≠tulo: \"$1k_F$\" Singularities and Finite Density ABJM Theory at Strong Coupling\n",
            "  Autores: Oscar Henriksson and Christopher Rosen\n",
            "  Referencia publicaci√≥n: None\n",
            "----------------------------------------\n",
            "4.T√≠tulo: \"$\\mathbf{{\\textit K^-}{\\textit p}{\\textit p}}$\", a\n",
            "  ${\\overline{K}}$-Meson Nuclear Bound State, Observed in $^{3}{\\rm He}({K^-},\n",
            "  {\\Lambda} p)n$ Reactions\n",
            "  Autores: J-PARC E15 collaboration, S. Ajimura, H. Asano, G. Beer, C. Berucci,\n",
            "  H. Bhang, M. Bragadireanu, P. Buehler, L. Busso, M. Cargnelli, S. Choi, C.\n",
            "  Curceanu, S. Enomoto, H. Fujioka, Y. Fujiwara, T. Fukuda, C. Guaraldo, T.\n",
            "  Hashimoto, R. S. Hayano, T. Hiraiwa, M. Iio, M. Iliescu, K. Inoue, Y.\n",
            "  Ishiguro, T. Ishikawa, S. Ishimoto, K. Itahashi, M. Iwasaki, K. Kanno, K.\n",
            "  Kato, Y. Kato, S. Kawasaki, P. Kienle, H. Kou, Y. Ma, J. Marton, Y. Matsuda,\n",
            "  Y. Mizoi, O. Morra, T. Nagae, H. Noumi, H. Ohnishi, S. Okada, H. Outa, K.\n",
            "  Piscicchia, Y. Sada, A. Sakaguchi, F. Sakuma, M. Sato, A. Scordo, M.\n",
            "  Sekimoto, H. Shi, K. Shirotori, D. Sirghi, F. Sirghi, K. Suzuki, S. Suzuki,\n",
            "  T. Suzuki, K. Tanida, H. Tatsuno, M. Tokuda, D. Tomono, A. Toyoda, K.\n",
            "  Tsukada, O. Vazquez Doce, E. Widmann, T. Yamaga, T. Yamazaki, Q. Zhang, and\n",
            "  J. Zmeskal\n",
            "  Referencia publicaci√≥n: None\n",
            "----------------------------------------\n",
            "5.T√≠tulo: \"'Formal' vs. 'Empirical' Approaches to Quantum-Classical Reduction\"\n",
            "  Autores: Joshua Rosaler\n",
            "  Referencia publicaci√≥n: Topoi Volume 34, Issue 2, pp 325-338, 2015\n",
            "----------------------------------------\n",
            "6.T√≠tulo: \"(Weitergeleitet von Journalistin)\": The Gendered Presentation of\n",
            "  Professions on Wikipedia\n",
            "  Autores: Olga Zagovora (1), Fabian Fl\\\"ock (1), Claudia Wagner (1 and 2) ((1)\n",
            "  GESIS - Leibniz Institute for the Social Sciences, (2) University of\n",
            "  Koblenz-Landau)\n",
            "  Referencia publicaci√≥n: None\n",
            "----------------------------------------\n",
            "7.T√≠tulo: \"+-+\" Brane Model Phenomenology\n",
            "  Autores: Stavros Mouslopoulos and Antonios Papazoglou (Oxford University)\n",
            "  Referencia publicaci√≥n: JHEP 0011 (2000) 018\n",
            "----------------------------------------\n",
            "8.T√≠tulo: \".. I didn't reflect much on what I was doing..\" How Planck discovered\n",
            "  his radiation formula\n",
            "  Autores: Domenico Giulini and Norbert Straumann (Univ. of Zuerich, Switzerland)\n",
            "  Referencia publicaci√≥n: None\n",
            "----------------------------------------\n",
            "9.T√≠tulo: \"0.7 anomaly\" and magnetic impurity formation in quantum point contacts\n",
            "  Autores: S. Ihnatsenka and I. V. Zozoulenko\n",
            "  Referencia publicaci√≥n: None\n",
            "----------------------------------------\n",
            "10.T√≠tulo: \"23andMe confirms: I'm super white\" -- Analyzing Twitter Discourse On\n",
            "  Genetic Testing\n",
            "  Autores: Alexandros Mittos, Jeremy Blackburn, Emiliano De Cristofaro\n",
            "  Referencia publicaci√≥n: None\n",
            "----------------------------------------\n",
            "11.T√≠tulo: \"420 Friendly\": Revealing Marijuana Use via Craigslist Rental Ads\n",
            "  Autores: Anh Nguyen, Long Nguyen, Dong Nguyen, Uyen Le and Tuan Tran\n",
            "  Referencia publicaci√≥n: None\n",
            "----------------------------------------\n",
            "12.T√≠tulo: \"4n multipole periodicity\" of the Galaxy image in the WMAP data\n",
            "  Autores: Pavel D. Naselsky, Igor D. Novikov (NBI)\n",
            "  Referencia publicaci√≥n: None\n",
            "----------------------------------------\n",
            "13.T√≠tulo: \"6 choose 4\": A framework to understand and facilitate discussion of\n",
            "  strategies for overall survival safety monitoring\n",
            "  Autores: Godwin Yung, Kaspar Rufibach, Marcel Wolbers, Mark Yan, Jue Wang\n",
            "  Referencia publicaci√≥n: None\n",
            "----------------------------------------\n",
            "14.T√≠tulo: \"A Good Bot Always Knows Its Limitations\": Assessing Autonomous System\n",
            "  Decision-making Competencies through Factorized Machine Self-confidence\n",
            "  Autores: Brett W. Israelsen, Nisar R. Ahmed, Matthew Aitken, Eric W. Frew, Dale\n",
            "  A. Lawrence, Brian M. Argrow\n",
            "  Referencia publicaci√≥n: None\n",
            "----------------------------------------\n",
            "15.T√≠tulo: \"A Great Start, But...\": Evaluating LLM-Generated Mind Maps for\n",
            "  Information Mapping in Video-Based Design\n",
            "  Autores: Tianhao He, Karthi Saravanan, Evangelos Niforatos, Gerd Kortuem\n",
            "  Referencia publicaci√≥n: None\n",
            "----------------------------------------\n",
            "16.T√≠tulo: \"A Handbook of Integer Sequences\" Fifty Years Later\n",
            "  Autores: N. J. A. Sloane\n",
            "  Referencia publicaci√≥n: None\n",
            "----------------------------------------\n",
            "17.T√≠tulo: \"A Hint From the Inter-Family Mass Hierarchy: Two Vector-Like Families\n",
            "  in the TeV range\"\n",
            "  Autores: K.S. Babu, Jogesh C. Pati and Hanns Stremnitzer\n",
            "  Referencia publicaci√≥n: Phys.Rev.D51:2451-2462,1995\n",
            "----------------------------------------\n",
            "18.T√≠tulo: \"A Little is Enough\": Few-Shot Quality Estimation based Corpus Filtering\n",
            "  improves Machine Translation\n",
            "  Autores: Akshay Batheja, Pushpak Bhattacharyya\n",
            "  Referencia publicaci√≥n: None\n",
            "----------------------------------------\n",
            "19.T√≠tulo: \"A Lot of Moving Parts\": A Case Study of Open-Source Hardware Design\n",
            "  Collaboration in the Thingiverse Community\n",
            "  Autores: Kathy Cheng, Shurui Zhou, Alison Olechowski\n",
            "  Referencia publicaci√≥n: None\n",
            "----------------------------------------\n",
            "20.T√≠tulo: \"A Nova Eletricidade: Aplica\\c{c}\\~oes, Riscos e Tend\\^encias da IA\n",
            "  Moderna -- \"The New Electricity\": Applications, Risks, and Trends in Current\n",
            "  AI\n",
            "  Autores: Ana L.C. Bazzan, Anderson R. Tavares, Andr\\'e G. Pereira, Cl\\'audio R.\n",
            "  Jung, Jacob Scharcanski, Joel Luis Carbonera, Lu\\'is C. Lamb, Mariana\n",
            "  Recamonde-Mendoza, Thiago L.T. da Silveira, Viviane Moreira\n",
            "  Referencia publicaci√≥n: None\n",
            "----------------------------------------\n"
          ]
        }
      ],
      "source": [
        "def leer_articulos_con_doi(collection):\n",
        "    \"\"\"\n",
        "    Devuelve t√≠tulos, autores y referencia de publicaci√≥n de art√≠culos con DOI.\n",
        "    Ordena alfab√©ticamente por t√≠tulo y limita a 20 resultados.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        cursor = collection.find(\n",
        "            {\"doi\": {\"$exists\": True, \"$ne\": \"\"}},\n",
        "            {\"_id\": 0, \"title\": 1, \"authors\": 1, \"journal-ref\": 1}).sort(\"title\", 1).limit(20)\n",
        "\n",
        "        resultados = []\n",
        "        for doc in cursor:\n",
        "            resultados.append({\n",
        "                \"titulo\": doc.get(\"title\", \"Sin t√≠tulo\"),\n",
        "                \"autores\": doc.get(\"authors\", []),\n",
        "                \"referencia_publicacion\": doc.get(\"journal-ref\", \"No disponible\")\n",
        "            })\n",
        "\n",
        "        if resultados:\n",
        "            print(\"Art√≠culos con DOI:\")\n",
        "            print()\n",
        "            i = 1\n",
        "            for art in resultados:\n",
        "                print(f\"{i}.T√≠tulo: {art['titulo']}\")\n",
        "                print(f\"  Autores: {art['autores']}\")\n",
        "                print(f\"  Referencia publicaci√≥n: {art['referencia_publicacion']}\")\n",
        "                print(\"-\" * 40)\n",
        "                i += 1\n",
        "        else:\n",
        "            print(\"No se encontraron art√≠culos con DOI.\")\n",
        "\n",
        "        return resultados\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error al buscar art√≠culos con DOI: {e}\")\n",
        "        return []\n",
        "\n",
        "articulos_encontrados = leer_articulos_con_doi(collection)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Consulta 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1. Titulo: A landscape of non-supersymmetric AdS vacua on coset manifolds\n",
            "  Primera versi√≥n: Mon, 4 Jan 2010 13:51:46 GMT\n",
            "--------------------------------------------------\n",
            "2. Titulo: Jet Shapes and Jet Algorithms in SCET\n",
            "  Primera versi√≥n: Mon, 4 Jan 2010 20:56:57 GMT\n",
            "--------------------------------------------------\n",
            "3. Titulo: A Comprehensive Analysis of Uncertainties Affecting the Stellar Mass -\n",
            "  Halo Mass Relation for 0<z<4\n",
            "  Primera versi√≥n: Sun, 3 Jan 2010 19:43:29 GMT\n",
            "--------------------------------------------------\n",
            "4. Titulo: Testing product states, quantum Merlin-Arthur games and tensor\n",
            "  optimisation\n",
            "  Primera versi√≥n: Mon, 4 Jan 2010 18:01:41 GMT\n",
            "--------------------------------------------------\n",
            "5. Titulo: Mu-Tau Production at Hadron Colliders\n",
            "  Primera versi√≥n: Mon, 4 Jan 2010 04:10:52 GMT\n",
            "--------------------------------------------------\n",
            "6. Titulo: New identities involving q-Euler polynomials of higher order\n",
            "  Primera versi√≥n: Mon, 4 Jan 2010 15:34:13 GMT\n",
            "--------------------------------------------------\n",
            "7. Titulo: Strong Constraints to the Putative Planet Candidate around VB 10 using\n",
            "  Doppler spectroscopy\n",
            "  Primera versi√≥n: Fri, 1 Jan 2010 00:07:58 GMT\n",
            "--------------------------------------------------\n",
            "8. Titulo: Arrested phase separation in reproducing bacteria: a generic route to\n",
            "  pattern formation?\n",
            "  Primera versi√≥n: Mon, 4 Jan 2010 19:56:03 GMT\n",
            "--------------------------------------------------\n",
            "9. Titulo: Euclid Imaging Consortium Science Book\n",
            "  Primera versi√≥n: Mon, 4 Jan 2010 15:34:42 GMT\n",
            "--------------------------------------------------\n",
            "10. Titulo: Bayesian Methods and Universal Darwinism\n",
            "  Primera versi√≥n: Mon, 4 Jan 2010 17:01:57 GMT\n",
            "--------------------------------------------------\n",
            "11. Titulo: News on PHOTOS Monte Carlo: gamma^* -> pi^+ pi^-(gamma) and K^\\pm ->\n",
            "  pi^+ pi^- e^\\pm nu (gamma)\n",
            "  Primera versi√≥n: Mon, 4 Jan 2010 15:50:15 GMT\n",
            "--------------------------------------------------\n",
            "12. Titulo: Nonmeasurability in Banach spaces\n",
            "  Primera versi√≥n: Mon, 4 Jan 2010 16:31:26 GMT\n",
            "--------------------------------------------------\n",
            "13. Titulo: Rigid Symmetries and Conservation Laws in Non-Lagrangian Field Theory\n",
            "  Primera versi√≥n: Mon, 4 Jan 2010 12:30:50 GMT\n",
            "--------------------------------------------------\n",
            "14. Titulo: The quadratic character of 1+\\sqrt{2} and an elliptic curve\n",
            "  Primera versi√≥n: Sun, 3 Jan 2010 04:16:44 GMT\n",
            "--------------------------------------------------\n",
            "15. Titulo: Collapsing and Separating Completeness Notions under Average-Case and\n",
            "  Worst-Case Hypotheses\n",
            "  Primera versi√≥n: Mon, 4 Jan 2010 20:55:05 GMT\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "def obtener_articulos_2010_2015(collection):\n",
        "    try:\n",
        "        # Expresi√≥n regular para a√±os del 2010 al 2015 en la fecha creada\n",
        "        regex = {\"$regex\": r\"201[0-5]\"}\n",
        "        \n",
        "        # Solo pedimos los art√≠culos con una primera versi√≥n que coincida\n",
        "        cursor = collection.find(\n",
        "            { \"versions.0.created\": regex },\n",
        "            { \"title\": 1, \"versions\": 1 }\n",
        "        ).limit(15)\n",
        "\n",
        "        resultados = []\n",
        "        for doc in cursor:\n",
        "            title = doc.get(\"title\", \"(sin t√≠tulo)\")\n",
        "            versiones = doc.get(\"versions\", [])\n",
        "            if versiones and \"created\" in versiones[0]:\n",
        "                fecha = versiones[0][\"created\"]\n",
        "            else:\n",
        "                fecha = \"¬øsin fecha?\"\n",
        "                \n",
        "            resultados.append({\n",
        "                \"title\": title,\n",
        "                \"fecha_primera_version\": fecha\n",
        "            })\n",
        "        i = 1\n",
        "        for r in resultados:\n",
        "            print(f\"{i}. Titulo: {r['title']}\")\n",
        "            print(f\"  Primera versi√≥n: {r['fecha_primera_version']}\")\n",
        "            print(\"-\" * 50)\n",
        "            i += 1\n",
        "\n",
        "        return resultados\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error ejecutando la consulta: {e}\")\n",
        "\n",
        "articulos_encontrados = obtener_articulos_2010_2015(collection)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Consulta 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1. T√≠tulo: Computing genus 2 Hilbert-Siegel modular forms over $\\Q(\\sqrt{5})$ via\n",
            "  the Jacquet-Langlands correspondence\n",
            "   Comentarios: 14 pages; title changed; to appear in Experimental Mathematics\n",
            "   N√∫mero de reporte: null\n",
            "--------------------------------------------------\n",
            "2. T√≠tulo: Iterated integral and the loop product\n",
            "   Comentarios: 18 pages, 1 figure\n",
            "   N√∫mero de reporte: null\n",
            "--------------------------------------------------\n",
            "3. T√≠tulo: Bosonic characters of atomic Cooper pairs across resonance\n",
            "   Comentarios: 6 pages, 4 figures, accepted by PRA\n",
            "   N√∫mero de reporte: null\n",
            "--------------------------------------------------\n",
            "4. T√≠tulo: Partial cubes: structures, characterizations, and constructions\n",
            "   Comentarios: 36 pages, 17 figures\n",
            "   N√∫mero de reporte: null\n",
            "--------------------------------------------------\n",
            "5. T√≠tulo: Polymer Quantum Mechanics and its Continuum Limit\n",
            "   Comentarios: 16 pages, no figures. Typos corrected to match published version\n",
            "   N√∫mero de reporte: null\n",
            "--------------------------------------------------\n",
            "6. T√≠tulo: A determinant of Stirling cycle numbers counts unlabeled acyclic\n",
            "  single-source automata\n",
            "   Comentarios: 11 pages\n",
            "   N√∫mero de reporte: null\n",
            "--------------------------------------------------\n",
            "7. T√≠tulo: Sparsity-certifying Graph Decompositions\n",
            "   Comentarios: To appear in Graphs and Combinatorics\n",
            "   N√∫mero de reporte: null\n",
            "--------------------------------------------------\n",
            "8. T√≠tulo: Calculation of prompt diphoton production cross sections at Tevatron and\n",
            "  LHC energies\n",
            "   Comentarios: 37 pages, 15 figures; published version\n",
            "   N√∫mero de reporte: null\n",
            "--------------------------------------------------\n",
            "9. T√≠tulo: The evolution of the Earth-Moon system based on the dark matter field\n",
            "  fluid model\n",
            "   Comentarios: 23 pages, 3 figures\n",
            "   N√∫mero de reporte: null\n",
            "--------------------------------------------------\n",
            "10. T√≠tulo: Numerical solution of shock and ramp compression for general material\n",
            "  properties\n",
            "   Comentarios: Minor corrections\n",
            "   N√∫mero de reporte: null\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "def obtener_articulos_no_nulos(collection):\n",
        "    try:\n",
        "        cursor = collection.find(\n",
        "            # Filtro para art√≠culos que tienen comentarios no nulos.\n",
        "            {\"comments\": {\"$exists\": True, \"$ne\": None}},\n",
        "            # Buscamos solo por titulo, comentarios y n√∫mero de reporte.\n",
        "            {\"title\": 1, \"comments\": 1, \"report-no\": 1}\n",
        "        ).sort(\"updated\", -1).limit(10)\n",
        "\n",
        "        resultados = []\n",
        "        for doc in cursor:\n",
        "            resultados.append({\n",
        "                \"title\": doc.get(\"title\", \"Sin t√≠tulo\"),\n",
        "                \"comments\": doc.get(\"comments\", []),\n",
        "                \"report_no\": doc.get(\"doi\", {}).get(\"report-no\", \"null\")\n",
        "            })\n",
        "        \n",
        "        return resultados\n",
        "    \n",
        "    except Exception as e:\n",
        "        print(f\"Error ejecutando la consulta: {e}\")\n",
        "\n",
        "articulos_encontrados = obtener_articulos_no_nulos(collection)\n",
        "i = 1\n",
        "for articulos in articulos_encontrados:\n",
        "    print(f\"{i}. T√≠tulo: {articulos['title']}\")\n",
        "    print(f\"   Comentarios: {articulos['comments']}\")\n",
        "    print(f\"   N√∫mero de reporte: {articulos['report_no']}\")\n",
        "    print(\"-\" * 50)\n",
        "    i += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "C√≥digo para asegurar consistencia de los datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Insertamos un dato \"test\" en el contenedor principal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Documento insertado en mongo1 con ID: 6848f0fed20bc43658f8e8c9\n"
          ]
        }
      ],
      "source": [
        "#Con el siguiente c√≥digo insertamos un documento de prueba en el nodo primario\n",
        "def insertar_en_nodoPrimario(collection, data):\n",
        "    try:\n",
        "        result = collection.insert_one(data)\n",
        "        print(f\"Documento insertado en mongo1 con ID: {result.inserted_id}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error al insertar en mongo1: {e}\")\n",
        "\n",
        "insertar_en_nodoPrimario(collection, {\"test\": \"replicacion_OK\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ahora, consultamos en los tres contenedores si se encuentra el dato \"test\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Dato encontrado en mongo1: {'_id': ObjectId('6848f0fed20bc43658f8e8c9'), 'test': 'replicacion_OK'}\n",
            "‚úÖ Dato encontrado en mongo2: {'_id': ObjectId('6848f0fed20bc43658f8e8c9'), 'test': 'replicacion_OK'}\n",
            "‚úÖ Dato encontrado en mongo3: {'_id': ObjectId('6848f0fed20bc43658f8e8c9'), 'test': 'replicacion_OK'}\n"
          ]
        }
      ],
      "source": [
        "#Ahora buscamos el dato insertado en cada nodo del Replica Set\n",
        "def buscar_dato_test_por_nodo(port, contenedor):\n",
        "    try:\n",
        "        client = MongoClient(f\"mongodb://localhost:{port}\", serverSelectionTimeoutMS=5000)\n",
        "        db = client[\"arxiv_db\"]\n",
        "        collection = db[\"articles\"]\n",
        "\n",
        "        result = collection.find_one({\"test\": \"replicacion_OK\"})\n",
        "        if result:\n",
        "            print(f\"-> Dato encontrado en {contenedor}: {result}\")\n",
        "        else:\n",
        "            print(f\"-> Dato no encontrado en {contenedor}.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error al buscar en {contenedor}: {e}\")\n",
        "\n",
        "#Llamamos por cada nodo si existe el dato insertado\n",
        "buscar_dato_test_por_nodo(27017, \"mongo1\")\n",
        "buscar_dato_test_por_nodo(27018, \"mongo2\")\n",
        "buscar_dato_test_por_nodo(27019, \"mongo3\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "En el siguiente paso, actualizamos el dato en el nodo principal y verificamos la replicaci√≥n en los otros nodos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No se encontr√≥ el dato para actualizar.\n",
            "--------------------------------------------------\n",
            "Dato encontrado en mongo1: {'_id': ObjectId('6848f0fed20bc43658f8e8c9'), 'test': 'Actualizado!'}\n",
            "Dato encontrado en mongo2: {'_id': ObjectId('6848f0fed20bc43658f8e8c9'), 'test': 'Actualizado!'}\n",
            "Dato encontrado en mongo3: {'_id': ObjectId('6848f0fed20bc43658f8e8c9'), 'test': 'Actualizado!'}\n"
          ]
        }
      ],
      "source": [
        "def actualizar_dato_test():\n",
        "    try:\n",
        "        # Actualizamos el campo \"test\" a \"Actualizado!\" en el nodo primario\n",
        "        result = collection.update_one(\n",
        "            {\"test\": \"replicacion_OK\"},\n",
        "            {\"$set\": {\"test\": \"Actualizado!\"}}\n",
        "        )\n",
        "        if result.modified_count > 0:\n",
        "            print(\"-> Dato actualizado correctamente.\")\n",
        "        else:\n",
        "            print(\"-> No se encontr√≥ el dato para actualizar.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error al actualizar el dato: {e}\")\n",
        "\n",
        "def buscar_dato_test_por_nodo(port, contenedor):\n",
        "    try:\n",
        "        client = MongoClient(f\"mongodb://localhost:{port}\", serverSelectionTimeoutMS=5000)\n",
        "        db = client[\"arxiv_db\"]\n",
        "        collection = db[\"articles\"]\n",
        "\n",
        "        result = collection.find_one({\"test\": \"Actualizado!\"})\n",
        "        if result:\n",
        "            print(f\"-> Dato encontrado en {contenedor}: {result}\")\n",
        "        else:\n",
        "            print(f\"-> Dato no encontrado en {contenedor}.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error al buscar en {contenedor}: {e}\")\n",
        "\n",
        "actualizar_dato_test()\n",
        "print(\"-\"*50)\n",
        "buscar_dato_test_por_nodo(27017, \"mongo1\")\n",
        "buscar_dato_test_por_nodo(27018, \"mongo2\")\n",
        "buscar_dato_test_por_nodo(27019, \"mongo3\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ahora borramos el dato que hemos actualizado y lo buscamos en los 3 contenedores para verificar efectivamente la consistencia de los datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-> Dato borrado correctamente.\n",
            "--------------------------------------------------\n",
            "-> Dato no encontrado en mongo1.\n",
            "-> Dato no encontrado en mongo2.\n",
            "-> Dato no encontrado en mongo3.\n"
          ]
        }
      ],
      "source": [
        "def borrar_dato_test():\n",
        "    try:\n",
        "        result = collection.delete_one({\"test\": \"Actualizado!\"})\n",
        "        if result.deleted_count > 0:\n",
        "            print(\"-> Dato borrado correctamente.\")\n",
        "        else:\n",
        "            print(\"-> No se encontr√≥ el dato para borrar.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error al borrar el dato: {e}\")\n",
        "\n",
        "def buscar_dato_test_por_nodo(port, contenedor):\n",
        "    try:\n",
        "        client = MongoClient(f\"mongodb://localhost:{port}\", serverSelectionTimeoutMS=5000)\n",
        "        db = client[\"arxiv_db\"]\n",
        "        collection = db[\"articles\"]\n",
        "\n",
        "        result = collection.find_one({\"test\": \"Actualizado!\"})\n",
        "        if result:\n",
        "            print(f\"-> Dato encontrado en {contenedor}: {result}\")\n",
        "        else:\n",
        "            print(f\"-> Dato no encontrado en {contenedor}.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error al buscar en {contenedor}: {e}\")\n",
        "\n",
        "borrar_dato_test()\n",
        "print(\"-\"*50)\n",
        "buscar_dato_test_por_nodo(27017, \"mongo1\")\n",
        "buscar_dato_test_por_nodo(27018, \"mongo2\")\n",
        "buscar_dato_test_por_nodo(27019, \"mongo3\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
